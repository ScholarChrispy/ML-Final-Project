{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **ML Final Project**:\n",
    "\n",
    "### **Group Members:**\n",
    "- Christopher Johnson (christopher.johnson13@ontariotechu.net)\n",
    "- Name (Student Email)\n",
    "- Name (Student Email)\n",
    "- Name (Student Email)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Project Goals & Outline:**\n",
    "The goal of this project is to use sentiment analysis to analyze the content of tweets, and make decisions on whether their sentiment is positive, negative, neutral, or irrelevant.\n",
    "\n",
    "### Outline:\n",
    "1. Data Importing and Preprocessing\n",
    "2. Model Construction\n",
    "   1. RNN\n",
    "   2. LSTM\n",
    "   3. ???\n",
    "3. Model Training\n",
    "   1. RNN\n",
    "   2. LSTM\n",
    "   3. ???\n",
    "4. Model Analysis and Comparison\n",
    "5. Conclusions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Importing Packages & Libraries:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# general packages/libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from datetime import datetime # used to convert Date_time strings to useable format\n",
    "\n",
    "# torch\n",
    "import torch\n",
    "\n",
    "# torchmetrics\n",
    "from torchmetrics import Accuracy\n",
    "\n",
    "# torchtext\n",
    "import torchtext.data\n",
    "from torchtext.vocab import build_vocab_from_iterator\n",
    "\n",
    "# lightning\n",
    "from lightning.pytorch import LightningModule\n",
    "from lightning.pytorch import Trainer\n",
    "from lightning.pytorch.loggers import CSVLogger\n",
    "\n",
    "# tqdm\n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Data Importing and Preprocessing:**\n",
    "This section is where the tweet data is imported and processed into tokens. This tokenization process is required so the neural network architectures can interpret the text data.\n",
    "\n",
    "**Tokenization definition:** the process of breaking down a sequence of information into smaller chunks known as tokens."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing the Dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Tweet ID</th>\n",
       "      <th>entity</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>Tweet content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2401</td>\n",
       "      <td>Borderlands</td>\n",
       "      <td>Positive</td>\n",
       "      <td>im getting on borderlands and i will murder yo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2401</td>\n",
       "      <td>Borderlands</td>\n",
       "      <td>Positive</td>\n",
       "      <td>I am coming to the borders and I will kill you...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2401</td>\n",
       "      <td>Borderlands</td>\n",
       "      <td>Positive</td>\n",
       "      <td>im getting on borderlands and i will kill you ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2401</td>\n",
       "      <td>Borderlands</td>\n",
       "      <td>Positive</td>\n",
       "      <td>im coming on borderlands and i will murder you...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2401</td>\n",
       "      <td>Borderlands</td>\n",
       "      <td>Positive</td>\n",
       "      <td>im getting on borderlands 2 and i will murder ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2401</td>\n",
       "      <td>Borderlands</td>\n",
       "      <td>Positive</td>\n",
       "      <td>im getting into borderlands and i can murder y...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2402</td>\n",
       "      <td>Borderlands</td>\n",
       "      <td>Positive</td>\n",
       "      <td>So I spent a few hours making something for fu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2402</td>\n",
       "      <td>Borderlands</td>\n",
       "      <td>Positive</td>\n",
       "      <td>So I spent a couple of hours doing something f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2402</td>\n",
       "      <td>Borderlands</td>\n",
       "      <td>Positive</td>\n",
       "      <td>So I spent a few hours doing something for fun...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2402</td>\n",
       "      <td>Borderlands</td>\n",
       "      <td>Positive</td>\n",
       "      <td>So I spent a few hours making something for fu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2402</td>\n",
       "      <td>Borderlands</td>\n",
       "      <td>Positive</td>\n",
       "      <td>2010 So I spent a few hours making something f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>2402</td>\n",
       "      <td>Borderlands</td>\n",
       "      <td>Positive</td>\n",
       "      <td>was</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>2403</td>\n",
       "      <td>Borderlands</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>Rock-Hard La Varlope, RARE &amp; POWERFUL, HANDSOM...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>2403</td>\n",
       "      <td>Borderlands</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>Rock-Hard La Varlope, RARE &amp; POWERFUL, HANDSOM...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>2403</td>\n",
       "      <td>Borderlands</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>Rock-Hard La Varlope, RARE &amp; POWERFUL, HANDSOM...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>2403</td>\n",
       "      <td>Borderlands</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>Rock-Hard La Vita, RARE BUT POWERFUL, HANDSOME...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>2403</td>\n",
       "      <td>Borderlands</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>Live Rock - Hard music La la Varlope, RARE &amp; t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>2403</td>\n",
       "      <td>Borderlands</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>I-Hard like me, RARE LONDON DE, HANDSOME 2011,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>2404</td>\n",
       "      <td>Borderlands</td>\n",
       "      <td>Positive</td>\n",
       "      <td>that was the first borderlands session in a lo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>2404</td>\n",
       "      <td>Borderlands</td>\n",
       "      <td>Positive</td>\n",
       "      <td>this was the first Borderlands session in a lo...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Tweet ID       entity sentiment  \\\n",
       "0       2401  Borderlands  Positive   \n",
       "1       2401  Borderlands  Positive   \n",
       "2       2401  Borderlands  Positive   \n",
       "3       2401  Borderlands  Positive   \n",
       "4       2401  Borderlands  Positive   \n",
       "5       2401  Borderlands  Positive   \n",
       "6       2402  Borderlands  Positive   \n",
       "7       2402  Borderlands  Positive   \n",
       "8       2402  Borderlands  Positive   \n",
       "9       2402  Borderlands  Positive   \n",
       "10      2402  Borderlands  Positive   \n",
       "11      2402  Borderlands  Positive   \n",
       "12      2403  Borderlands   Neutral   \n",
       "13      2403  Borderlands   Neutral   \n",
       "14      2403  Borderlands   Neutral   \n",
       "15      2403  Borderlands   Neutral   \n",
       "16      2403  Borderlands   Neutral   \n",
       "17      2403  Borderlands   Neutral   \n",
       "18      2404  Borderlands  Positive   \n",
       "19      2404  Borderlands  Positive   \n",
       "\n",
       "                                        Tweet content  \n",
       "0   im getting on borderlands and i will murder yo...  \n",
       "1   I am coming to the borders and I will kill you...  \n",
       "2   im getting on borderlands and i will kill you ...  \n",
       "3   im coming on borderlands and i will murder you...  \n",
       "4   im getting on borderlands 2 and i will murder ...  \n",
       "5   im getting into borderlands and i can murder y...  \n",
       "6   So I spent a few hours making something for fu...  \n",
       "7   So I spent a couple of hours doing something f...  \n",
       "8   So I spent a few hours doing something for fun...  \n",
       "9   So I spent a few hours making something for fu...  \n",
       "10  2010 So I spent a few hours making something f...  \n",
       "11                                                was  \n",
       "12  Rock-Hard La Varlope, RARE & POWERFUL, HANDSOM...  \n",
       "13  Rock-Hard La Varlope, RARE & POWERFUL, HANDSOM...  \n",
       "14  Rock-Hard La Varlope, RARE & POWERFUL, HANDSOM...  \n",
       "15  Rock-Hard La Vita, RARE BUT POWERFUL, HANDSOME...  \n",
       "16  Live Rock - Hard music La la Varlope, RARE & t...  \n",
       "17  I-Hard like me, RARE LONDON DE, HANDSOME 2011,...  \n",
       "18  that was the first borderlands session in a lo...  \n",
       "19  this was the first Borderlands session in a lo...  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import the tweet data from the CSV using pandas\n",
    "tweet_data = pd.read_csv('./Datasets/twitter_training.csv', names=['Tweet ID', 'entity', 'sentiment', 'Tweet content'])\n",
    "tweet_data.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0     im getting on borderlands and i will murder yo...\n",
      "1     I am coming to the borders and I will kill you...\n",
      "2     im getting on borderlands and i will kill you ...\n",
      "3     im coming on borderlands and i will murder you...\n",
      "4     im getting on borderlands 2 and i will murder ...\n",
      "5     im getting into borderlands and i can murder y...\n",
      "6     So I spent a few hours making something for fu...\n",
      "7     So I spent a couple of hours doing something f...\n",
      "8     So I spent a few hours doing something for fun...\n",
      "9     So I spent a few hours making something for fu...\n",
      "10    2010 So I spent a few hours making something f...\n",
      "11                                                  was\n",
      "12    Rock-Hard La Varlope, RARE & POWERFUL, HANDSOM...\n",
      "13    Rock-Hard La Varlope, RARE & POWERFUL, HANDSOM...\n",
      "14    Rock-Hard La Varlope, RARE & POWERFUL, HANDSOM...\n",
      "15    Rock-Hard La Vita, RARE BUT POWERFUL, HANDSOME...\n",
      "16    Live Rock - Hard music La la Varlope, RARE & t...\n",
      "17    I-Hard like me, RARE LONDON DE, HANDSOME 2011,...\n",
      "18    that was the first borderlands session in a lo...\n",
      "19    this was the first Borderlands session in a lo...\n",
      "Name: Tweet content, dtype: object\n"
     ]
    }
   ],
   "source": [
    "# extracting the the tweet content for ease of use\n",
    "content = tweet_data['Tweet content']\n",
    "\n",
    "# TODO: (if necessary) preprocess the content\n",
    "# e.g. remove any nonsense or very short tweets\n",
    "\n",
    "# showing the extracted content\n",
    "print(content.head(20))\n",
    "\n",
    "# convert content to an iterator\n",
    "content = iter(content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0     0\n",
      "1     0\n",
      "2     0\n",
      "3     0\n",
      "4     0\n",
      "5     0\n",
      "6     0\n",
      "7     0\n",
      "8     0\n",
      "9     0\n",
      "10    0\n",
      "11    0\n",
      "12    2\n",
      "13    2\n",
      "14    2\n",
      "15    2\n",
      "16    2\n",
      "17    2\n",
      "18    0\n",
      "19    0\n",
      "Name: sentiment, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# extracting the the sentiment data for ease of use\n",
    "sentiment = tweet_data['sentiment']\n",
    "\n",
    "# the numerical representations of the sentiment values\n",
    "sentiment_numerical = {\n",
    "    'Positive': 0,\n",
    "    'Negative': 1,\n",
    "    'Neutral': 2,\n",
    "    'Irrelevant': 3\n",
    "}\n",
    "\n",
    "# converting the sentiment data into a numerical form\n",
    "sentiment.replace(to_replace=sentiment_numerical, inplace=True)\n",
    "\n",
    "# showing the converted sentiment data\n",
    "print(sentiment.head(20))\n",
    "\n",
    "# converting the sentiment data into a torch tensor\n",
    "sentiment = torch.tensor(sentiment, dtype=torch.int64)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tokenization:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Fix tokenizer\n",
    "\n",
    "# tokenizer = torchtext.data.get_tokenizer('basic_english')\n",
    "\n",
    "# # creates tokens from a given dataframe\n",
    "# def create_tokens(values):\n",
    "#     for val in tqdm(values):\n",
    "#         print(val)\n",
    "#         yield tokenizer(val)\n",
    "\n",
    "# # create the vocab from the content data\n",
    "# vocab = build_vocab_from_iterator(\n",
    "#     create_tokens(content),\n",
    "#     min_freq=5,\n",
    "#     specials=['<unk>', '<s>', '<eos>']\n",
    "# )\n",
    "# vocab.set_default_index(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Model Creation:**\n",
    "This is where the models being used are defined."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **RNN Model:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
