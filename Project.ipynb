{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **ML Final Project**:\n",
    "\n",
    "### **Group Members:**\n",
    "- Christopher Johnson (christopher.johnson13@ontariotechu.net)\n",
    "- Name (Student Email)\n",
    "- Name (Student Email)\n",
    "- Name (Student Email)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Project Goals & Outline:**\n",
    "The goal of this project is to use sentiment analysis to analyze the content of tweets, and make decisions on whether their sentiment is positive, negative, or neutral.\n",
    "\n",
    "### Outline:\n",
    "1. Data Importing and Preprocessing\n",
    "2. Model Construction\n",
    "   1. RNN\n",
    "   2. LSTM\n",
    "   3. ???\n",
    "3. Model Training\n",
    "   1. RNN\n",
    "   2. LSTM\n",
    "   3. ???\n",
    "4. Model Analysis and Comparison\n",
    "5. Conclusions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Importing Packages & Libraries:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\chris\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# general packages/libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from datetime import datetime # used to convert Date_time strings to useable format\n",
    "\n",
    "# torch\n",
    "import torch\n",
    "\n",
    "# torchmetrics\n",
    "from torchmetrics import Accuracy\n",
    "\n",
    "# torchtext\n",
    "import torchtext.data\n",
    "from torchtext.vocab import build_vocab_from_iterator\n",
    "\n",
    "# lightning\n",
    "from lightning.pytorch import LightningModule\n",
    "from lightning.pytorch import Trainer\n",
    "from lightning.pytorch.loggers import CSVLogger\n",
    "\n",
    "# tqdm\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "# nltk\n",
    "import nltk # used for tokenziation\n",
    "nltk.download('punkt')\n",
    "from nltk import word_tokenize\n",
    "\n",
    "# regular expressions\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Data Importing and Preprocessing:**\n",
    "This section is where the tweet data is imported and processed into tokens. This tokenization process is required so the neural network architectures can interpret the text data.\n",
    "\n",
    "**Tokenization definition:** the process of breaking down a sequence of information into smaller chunks known as tokens."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing the Dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Tweet ID</th>\n",
       "      <th>entity</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>Tweet content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2401</td>\n",
       "      <td>Borderlands</td>\n",
       "      <td>Positive</td>\n",
       "      <td>im getting on borderlands and i will murder yo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2401</td>\n",
       "      <td>Borderlands</td>\n",
       "      <td>Positive</td>\n",
       "      <td>I am coming to the borders and I will kill you...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2401</td>\n",
       "      <td>Borderlands</td>\n",
       "      <td>Positive</td>\n",
       "      <td>im getting on borderlands and i will kill you ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2401</td>\n",
       "      <td>Borderlands</td>\n",
       "      <td>Positive</td>\n",
       "      <td>im coming on borderlands and i will murder you...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2401</td>\n",
       "      <td>Borderlands</td>\n",
       "      <td>Positive</td>\n",
       "      <td>im getting on borderlands 2 and i will murder ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2401</td>\n",
       "      <td>Borderlands</td>\n",
       "      <td>Positive</td>\n",
       "      <td>im getting into borderlands and i can murder y...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2402</td>\n",
       "      <td>Borderlands</td>\n",
       "      <td>Positive</td>\n",
       "      <td>So I spent a few hours making something for fu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2402</td>\n",
       "      <td>Borderlands</td>\n",
       "      <td>Positive</td>\n",
       "      <td>So I spent a couple of hours doing something f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2402</td>\n",
       "      <td>Borderlands</td>\n",
       "      <td>Positive</td>\n",
       "      <td>So I spent a few hours doing something for fun...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2402</td>\n",
       "      <td>Borderlands</td>\n",
       "      <td>Positive</td>\n",
       "      <td>So I spent a few hours making something for fu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2402</td>\n",
       "      <td>Borderlands</td>\n",
       "      <td>Positive</td>\n",
       "      <td>2010 So I spent a few hours making something f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>2402</td>\n",
       "      <td>Borderlands</td>\n",
       "      <td>Positive</td>\n",
       "      <td>was</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>2403</td>\n",
       "      <td>Borderlands</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>Rock-Hard La Varlope, RARE &amp; POWERFUL, HANDSOM...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>2403</td>\n",
       "      <td>Borderlands</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>Rock-Hard La Varlope, RARE &amp; POWERFUL, HANDSOM...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>2403</td>\n",
       "      <td>Borderlands</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>Rock-Hard La Varlope, RARE &amp; POWERFUL, HANDSOM...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>2403</td>\n",
       "      <td>Borderlands</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>Rock-Hard La Vita, RARE BUT POWERFUL, HANDSOME...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>2403</td>\n",
       "      <td>Borderlands</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>Live Rock - Hard music La la Varlope, RARE &amp; t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>2403</td>\n",
       "      <td>Borderlands</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>I-Hard like me, RARE LONDON DE, HANDSOME 2011,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>2404</td>\n",
       "      <td>Borderlands</td>\n",
       "      <td>Positive</td>\n",
       "      <td>that was the first borderlands session in a lo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>2404</td>\n",
       "      <td>Borderlands</td>\n",
       "      <td>Positive</td>\n",
       "      <td>this was the first Borderlands session in a lo...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Tweet ID       entity sentiment  \\\n",
       "0       2401  Borderlands  Positive   \n",
       "1       2401  Borderlands  Positive   \n",
       "2       2401  Borderlands  Positive   \n",
       "3       2401  Borderlands  Positive   \n",
       "4       2401  Borderlands  Positive   \n",
       "5       2401  Borderlands  Positive   \n",
       "6       2402  Borderlands  Positive   \n",
       "7       2402  Borderlands  Positive   \n",
       "8       2402  Borderlands  Positive   \n",
       "9       2402  Borderlands  Positive   \n",
       "10      2402  Borderlands  Positive   \n",
       "11      2402  Borderlands  Positive   \n",
       "12      2403  Borderlands   Neutral   \n",
       "13      2403  Borderlands   Neutral   \n",
       "14      2403  Borderlands   Neutral   \n",
       "15      2403  Borderlands   Neutral   \n",
       "16      2403  Borderlands   Neutral   \n",
       "17      2403  Borderlands   Neutral   \n",
       "18      2404  Borderlands  Positive   \n",
       "19      2404  Borderlands  Positive   \n",
       "\n",
       "                                        Tweet content  \n",
       "0   im getting on borderlands and i will murder yo...  \n",
       "1   I am coming to the borders and I will kill you...  \n",
       "2   im getting on borderlands and i will kill you ...  \n",
       "3   im coming on borderlands and i will murder you...  \n",
       "4   im getting on borderlands 2 and i will murder ...  \n",
       "5   im getting into borderlands and i can murder y...  \n",
       "6   So I spent a few hours making something for fu...  \n",
       "7   So I spent a couple of hours doing something f...  \n",
       "8   So I spent a few hours doing something for fun...  \n",
       "9   So I spent a few hours making something for fu...  \n",
       "10  2010 So I spent a few hours making something f...  \n",
       "11                                                was  \n",
       "12  Rock-Hard La Varlope, RARE & POWERFUL, HANDSOM...  \n",
       "13  Rock-Hard La Varlope, RARE & POWERFUL, HANDSOM...  \n",
       "14  Rock-Hard La Varlope, RARE & POWERFUL, HANDSOM...  \n",
       "15  Rock-Hard La Vita, RARE BUT POWERFUL, HANDSOME...  \n",
       "16  Live Rock - Hard music La la Varlope, RARE & t...  \n",
       "17  I-Hard like me, RARE LONDON DE, HANDSOME 2011,...  \n",
       "18  that was the first borderlands session in a lo...  \n",
       "19  this was the first Borderlands session in a lo...  "
      ]
     },
     "execution_count": 213,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import the tweet data from the CSV using pandas\n",
    "tweet_data = pd.read_csv('./Datasets/twitter_training.csv', names=['Tweet ID', 'entity', 'sentiment', 'Tweet content'])\n",
    "tweet_data.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sentiment\n",
       "Negative    22542\n",
       "Positive    20832\n",
       "Neutral     18318\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 214,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# droppping \"irrelevant\" sentiment values\n",
    "tweet_data.drop(\n",
    "    tweet_data[tweet_data['sentiment'] == 'Irrelevant'].index,\n",
    "    inplace=True\n",
    ")\n",
    "\n",
    "# showing remaining sentiment distribution\n",
    "tweet_data['sentiment'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0     im getting on borderlands and i will murder yo...\n",
      "1     I am coming to the borders and I will kill you...\n",
      "2     im getting on borderlands and i will kill you ...\n",
      "3     im coming on borderlands and i will murder you...\n",
      "4     im getting on borderlands 2 and i will murder ...\n",
      "5     im getting into borderlands and i can murder y...\n",
      "6     So I spent a few hours making something for fu...\n",
      "7     So I spent a couple of hours doing something f...\n",
      "8     So I spent a few hours doing something for fun...\n",
      "9     So I spent a few hours making something for fu...\n",
      "10    2010 So I spent a few hours making something f...\n",
      "11                                                  was\n",
      "12    Rock-Hard La Varlope, RARE & POWERFUL, HANDSOM...\n",
      "13    Rock-Hard La Varlope, RARE & POWERFUL, HANDSOM...\n",
      "14    Rock-Hard La Varlope, RARE & POWERFUL, HANDSOM...\n",
      "15    Rock-Hard La Vita, RARE BUT POWERFUL, HANDSOME...\n",
      "16    Live Rock - Hard music La la Varlope, RARE & t...\n",
      "17    I-Hard like me, RARE LONDON DE, HANDSOME 2011,...\n",
      "18    that was the first borderlands session in a lo...\n",
      "19    this was the first Borderlands session in a lo...\n",
      "20    that was the first borderlands session in a lo...\n",
      "21    that was the first borderlands session in a lo...\n",
      "22    that I was the first real borderlands session ...\n",
      "23    that was the first borderlands session in a ho...\n",
      "24    the biggest dissappoinment in my life came out...\n",
      "25    The biggest disappointment of my life came a y...\n",
      "26    The biggest disappointment of my life came a y...\n",
      "27    the biggest dissappoinment in my life coming o...\n",
      "28    For the biggest male dissappoinment in my life...\n",
      "29    the biggest dissappoinment in my life came bac...\n",
      "30    WE FINISHED BORDERLANDS 3 FINALLY YAS! Thank y...\n",
      "31    WE FINALLY FINALLY FIND BORDERLANDS 3 YES! Tha...\n",
      "32    Thank you for hanging up everyone! It was fun....\n",
      "33    WE FINISHED BORDERLANDS 3 UPDATE YAS! Thank yo...\n",
      "34    WE FINISHED BORDERLANDS 3 AND FINALLY YAS! Tha...\n",
      "35    WE FINISHED BORDERLANDS 3 FINALLY YAS! Hey you...\n",
      "36    Man Gearbox really needs to fix this dissapoin...\n",
      "37    Man Gearbox really needs to fix these disappoi...\n",
      "38    Man Gearbox really needs to fix this disssapoi...\n",
      "39    Man Bethesda really needs to fix this dissapoi...\n",
      "40    Man Gearbox really needs to fix this dissapoin...\n",
      "41    <unk> Gearbox really time to fix this 10 drops...\n",
      "42                     Check out this epic streamer!.  \n",
      "43                       Check out this epic streamer!.\n",
      "44                         Watch this epic striptease!.\n",
      "45                        Check out our epic streamer!.\n",
      "46                   Check out this big epic streamer!.\n",
      "47                      Check<unk> this epic streamer!.\n",
      "48    Blaming Sight for Tardiness! A little bit of b...\n",
      "49    A bit of borderland. I was called to work tomo...\n",
      "50    Guilty of sobriety! A bit of a borderline. I w...\n",
      "51    Blaming Sight for Tardiness! A little bit of b...\n",
      "52    for Blaming Sight for Tardiness! A little bit ...\n",
      "53                                                  all\n",
      "54    why does like every man in borderlands have sl...\n",
      "55    Why, like every man in border countries, have ...\n",
      "56    Why, like everyone else in the border countrie...\n",
      "57    why does like<unk> man in borderlands have sli...\n",
      "58    why Beth does like every man in borderlands ha...\n",
      "59    why does practically every man in France have ...\n",
      "Name: Tweet content, dtype: object\n"
     ]
    }
   ],
   "source": [
    "# extracting the the tweet content for ease of use\n",
    "content = tweet_data['Tweet content']\n",
    "\n",
    "# showing the extracted content\n",
    "print(content.head(60))\n",
    "\n",
    "# convert content to an iterator\n",
    "# content = iter(content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "method that processes content and removes the following content:\n",
    "- 1 word tweets\n",
    "- tweets that contain only special characters (e.g. /, ., <, etc.)\n",
    "'''\n",
    "def process_content(values:pd.Series):\n",
    "    # convert series to list\n",
    "    values = values.to_list()\n",
    "\n",
    "    # records the number of tweets removed\n",
    "    # (used to adjust the access index)\n",
    "    num_removed = 0\n",
    "\n",
    "    # #! DEBUG\n",
    "    # url_matches = 0\n",
    "\n",
    "    for i in tqdm(range(0, len(values))):\n",
    "        # checks for 1 word tweet using a tokenizer\n",
    "        if (len(word_tokenize(str(values[i - num_removed]))) <= 1):\n",
    "            # print('(1) ', i, ': ', str(values[i - num_removed]))  #! DEBUG\n",
    "            del values[i - num_removed]     # remove the tweet from the list\n",
    "            num_removed += 1     # count the number of removed tweets\n",
    "\n",
    "        # checks for tweets with only \"...\", \" \", \"[\" or, \"]\"\n",
    "        # (only removes the tweet if the match is >=75% of the tweet content)\n",
    "        if (len(re.match(r'^(\\.|\\[|\\]| |\\n|[0-9])*', str(values[i - num_removed])).group(0)) >= int(len(str(values[i - num_removed]))*0.75)):\n",
    "            # print('(2) ', i, ': ', str(values[i - num_removed]))  #! DEBUG\n",
    "            del values[i - num_removed]     # remove the tweet from the list\n",
    "            num_removed += 1     # count the number of removed tweets\n",
    "\n",
    "        url_match = re.match(r'(https?:\\ */\\ */\\ *)?(?:www\\.)?[a-zA-Z0-9.-]+\\.[a-zA-Z]{2,}(?:\\ */\\ *[^\\s]*)?', str(values[i - num_removed]))\n",
    "\n",
    "        # removes the tweets with links if a match exists\n",
    "        # if (url_match):\n",
    "        #     print('(3) ', i, ': ', url_match.group(0))  #! DEBUG\n",
    "        #     # del values[i - num_removed]     # remove the tweet from the list\n",
    "        #     # num_removed += 1     # count the number of removed tweets\n",
    "\n",
    "        #     #! DEBUG\n",
    "        #     url_matches += 1\n",
    "\n",
    "    # #! DEBUG\n",
    "    # print(url_matches)\n",
    "    return pd.Series(values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b8aecf5f7f734496b3caf3c67453e56a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/61692 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "0     im getting on borderlands and i will murder yo...\n",
       "1     I am coming to the borders and I will kill you...\n",
       "2     im getting on borderlands and i will kill you ...\n",
       "3     im coming on borderlands and i will murder you...\n",
       "4     im getting on borderlands 2 and i will murder ...\n",
       "5     im getting into borderlands and i can murder y...\n",
       "6     So I spent a few hours making something for fu...\n",
       "7     So I spent a couple of hours doing something f...\n",
       "8     So I spent a few hours doing something for fun...\n",
       "9     So I spent a few hours making something for fu...\n",
       "10    2010 So I spent a few hours making something f...\n",
       "11    Rock-Hard La Varlope, RARE & POWERFUL, HANDSOM...\n",
       "12    Rock-Hard La Varlope, RARE & POWERFUL, HANDSOM...\n",
       "13    Rock-Hard La Varlope, RARE & POWERFUL, HANDSOM...\n",
       "14    Rock-Hard La Vita, RARE BUT POWERFUL, HANDSOME...\n",
       "15    Live Rock - Hard music La la Varlope, RARE & t...\n",
       "16    I-Hard like me, RARE LONDON DE, HANDSOME 2011,...\n",
       "17    that was the first borderlands session in a lo...\n",
       "18    this was the first Borderlands session in a lo...\n",
       "19    that was the first borderlands session in a lo...\n",
       "dtype: object"
      ]
     },
     "execution_count": 217,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "content = process_content(content)\n",
    "content.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0     0\n",
      "1     0\n",
      "2     0\n",
      "3     0\n",
      "4     0\n",
      "5     0\n",
      "6     0\n",
      "7     0\n",
      "8     0\n",
      "9     0\n",
      "10    0\n",
      "11    0\n",
      "12    2\n",
      "13    2\n",
      "14    2\n",
      "15    2\n",
      "16    2\n",
      "17    2\n",
      "18    0\n",
      "19    0\n",
      "Name: sentiment, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# extracting the the sentiment data for ease of use\n",
    "sentiment = tweet_data['sentiment']\n",
    "\n",
    "# the numerical representations of the sentiment values\n",
    "sentiment_numerical = {\n",
    "    'Positive': 0,\n",
    "    'Negative': 1,\n",
    "    'Neutral': 2,\n",
    "}\n",
    "\n",
    "# converting the sentiment data into a numerical form\n",
    "sentiment.replace(to_replace=sentiment_numerical, inplace=True)\n",
    "\n",
    "# showing the converted sentiment data\n",
    "print(sentiment.head(20))\n",
    "\n",
    "# converting the sentiment data into a torch tensor\n",
    "sentiment = torch.tensor(sentiment, dtype=torch.int64)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tokenization:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'>\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0ad7a752420f42f0a85bb93422e9d8bd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/59441 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tokens = word_tokenize(content[0])\n",
    "print(type(tokens))\n",
    "\n",
    "def iterate_tokens(df):\n",
    "    for val in tqdm(df):\n",
    "        yield word_tokenize(str(val))\n",
    "\n",
    "vocab = build_vocab_from_iterator(\n",
    "    iterate_tokens(content),\n",
    "    min_freq = 5,\n",
    "    specials = ['<unk>']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['<unk>', '.', 'the', 'I', ',', '@', '!', 'to', 'and', 'a']"
      ]
     },
     "execution_count": 220,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab.lookup_tokens([0,1,2,3,4,5,6,7,8,9,])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Model Creation:**\n",
    "This is where the models being used are defined."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **RNN Model:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
