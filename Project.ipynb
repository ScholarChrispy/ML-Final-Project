{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **ML Final Project**:\n",
    "\n",
    "### **Group Members:**\n",
    "- Christopher Johnson (christopher.johnson13@ontariotechu.net)\n",
    "- Alexander Sawatzky (alexander.sawatzky@ontariotechu.net)\n",
    "- Cameron Millar (cameron.millar@ontariotechu.net)\n",
    "- Jack Udeschini (jack.udeschini@ontariotechu.net)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Project Goals & Outline:**\n",
    "The goal of this project is to use sentiment analysis to analyze the content of tweets, and make decisions on whether their sentiment is positive, negative, or neutral.\n",
    "\n",
    "### Outline:\n",
    "1. Data Importing and Preprocessing\n",
    "2. Model Construction\n",
    "   1. Recurrent Neural Network (RNN)\n",
    "   2. Long Short-Term Memory (LSTM)\n",
    "   3. Gated Recurrent Unit (GRU)\n",
    "   4. Transformer\n",
    "3. Model Training\n",
    "   1. Training RNN Network\n",
    "   2. Training LSTM Network\n",
    "   3. Training GRU Network\n",
    "   4. Training Transformer Network\n",
    "4. Model Analysis and Comparison\n",
    "   1. Analysis of RNN Model\n",
    "   2. Analysis of LSTM Model\n",
    "   3. Analysis of GRU Model\n",
    "   4. Analysis of the Transformer Model\n",
    "   5. Model Comparison\n",
    "5. Conclusions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Importing Packages & Libraries:**\n",
    "\n",
    "**Note:** Some libraries are imported automatically, while others have to be acquired manually."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: lightning in c:\\users\\chris\\anaconda3\\lib\\site-packages (2.1.1)\n",
      "Requirement already satisfied: PyYAML<8.0,>=5.4 in c:\\users\\chris\\anaconda3\\lib\\site-packages (from lightning) (6.0.1)\n",
      "Requirement already satisfied: fsspec[http]<2025.0,>2021.06.0 in c:\\users\\chris\\anaconda3\\lib\\site-packages (from lightning) (2023.4.0)\n",
      "Requirement already satisfied: lightning-utilities<2.0,>=0.8.0 in c:\\users\\chris\\anaconda3\\lib\\site-packages (from lightning) (0.9.0)\n",
      "Requirement already satisfied: numpy<3.0,>=1.17.2 in c:\\users\\chris\\anaconda3\\lib\\site-packages (from lightning) (1.24.3)\n",
      "Requirement already satisfied: packaging<25.0,>=20.0 in c:\\users\\chris\\anaconda3\\lib\\site-packages (from lightning) (23.1)\n",
      "Requirement already satisfied: torch<4.0,>=1.12.0 in c:\\users\\chris\\anaconda3\\lib\\site-packages (from lightning) (2.1.1)\n",
      "Requirement already satisfied: torchmetrics<3.0,>=0.7.0 in c:\\users\\chris\\anaconda3\\lib\\site-packages (from lightning) (1.2.0)\n",
      "Requirement already satisfied: tqdm<6.0,>=4.57.0 in c:\\users\\chris\\anaconda3\\lib\\site-packages (from lightning) (4.65.0)\n",
      "Requirement already satisfied: typing-extensions<6.0,>=4.0.0 in c:\\users\\chris\\anaconda3\\lib\\site-packages (from lightning) (4.7.1)\n",
      "Requirement already satisfied: pytorch-lightning in c:\\users\\chris\\anaconda3\\lib\\site-packages (from lightning) (2.1.1)\n",
      "Requirement already satisfied: requests in c:\\users\\chris\\anaconda3\\lib\\site-packages (from fsspec[http]<2025.0,>2021.06.0->lightning) (2.31.0)\n",
      "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in c:\\users\\chris\\anaconda3\\lib\\site-packages (from fsspec[http]<2025.0,>2021.06.0->lightning) (3.8.5)\n",
      "Requirement already satisfied: filelock in c:\\users\\chris\\anaconda3\\lib\\site-packages (from torch<4.0,>=1.12.0->lightning) (3.9.0)\n",
      "Requirement already satisfied: sympy in c:\\users\\chris\\anaconda3\\lib\\site-packages (from torch<4.0,>=1.12.0->lightning) (1.11.1)\n",
      "Requirement already satisfied: networkx in c:\\users\\chris\\anaconda3\\lib\\site-packages (from torch<4.0,>=1.12.0->lightning) (3.1)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\chris\\anaconda3\\lib\\site-packages (from torch<4.0,>=1.12.0->lightning) (3.1.2)\n",
      "Requirement already satisfied: colorama in c:\\users\\chris\\anaconda3\\lib\\site-packages (from tqdm<6.0,>=4.57.0->lightning) (0.4.6)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\chris\\anaconda3\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2025.0,>2021.06.0->lightning) (23.1.0)\n",
      "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in c:\\users\\chris\\anaconda3\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2025.0,>2021.06.0->lightning) (2.0.4)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\chris\\anaconda3\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2025.0,>2021.06.0->lightning) (6.0.2)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in c:\\users\\chris\\anaconda3\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2025.0,>2021.06.0->lightning) (4.0.2)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in c:\\users\\chris\\anaconda3\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2025.0,>2021.06.0->lightning) (1.8.1)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\chris\\anaconda3\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2025.0,>2021.06.0->lightning) (1.4.0)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in c:\\users\\chris\\anaconda3\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2025.0,>2021.06.0->lightning) (1.2.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\chris\\anaconda3\\lib\\site-packages (from jinja2->torch<4.0,>=1.12.0->lightning) (2.1.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\chris\\anaconda3\\lib\\site-packages (from requests->fsspec[http]<2025.0,>2021.06.0->lightning) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\chris\\anaconda3\\lib\\site-packages (from requests->fsspec[http]<2025.0,>2021.06.0->lightning) (1.26.18)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\chris\\anaconda3\\lib\\site-packages (from requests->fsspec[http]<2025.0,>2021.06.0->lightning) (2023.7.22)\n",
      "Requirement already satisfied: mpmath>=0.19 in c:\\users\\chris\\anaconda3\\lib\\site-packages (from sympy->torch<4.0,>=1.12.0->lightning) (1.3.0)\n",
      "Requirement already satisfied: torchmetrics in c:\\users\\chris\\anaconda3\\lib\\site-packages (1.2.0)\n",
      "Requirement already satisfied: numpy>1.20.0 in c:\\users\\chris\\anaconda3\\lib\\site-packages (from torchmetrics) (1.24.3)\n",
      "Requirement already satisfied: torch>=1.8.1 in c:\\users\\chris\\anaconda3\\lib\\site-packages (from torchmetrics) (2.1.1)\n",
      "Requirement already satisfied: lightning-utilities>=0.8.0 in c:\\users\\chris\\anaconda3\\lib\\site-packages (from torchmetrics) (0.9.0)\n",
      "Requirement already satisfied: packaging>=17.1 in c:\\users\\chris\\anaconda3\\lib\\site-packages (from lightning-utilities>=0.8.0->torchmetrics) (23.1)\n",
      "Requirement already satisfied: typing-extensions in c:\\users\\chris\\anaconda3\\lib\\site-packages (from lightning-utilities>=0.8.0->torchmetrics) (4.7.1)\n",
      "Requirement already satisfied: filelock in c:\\users\\chris\\anaconda3\\lib\\site-packages (from torch>=1.8.1->torchmetrics) (3.9.0)\n",
      "Requirement already satisfied: sympy in c:\\users\\chris\\anaconda3\\lib\\site-packages (from torch>=1.8.1->torchmetrics) (1.11.1)\n",
      "Requirement already satisfied: networkx in c:\\users\\chris\\anaconda3\\lib\\site-packages (from torch>=1.8.1->torchmetrics) (3.1)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\chris\\anaconda3\\lib\\site-packages (from torch>=1.8.1->torchmetrics) (3.1.2)\n",
      "Requirement already satisfied: fsspec in c:\\users\\chris\\anaconda3\\lib\\site-packages (from torch>=1.8.1->torchmetrics) (2023.4.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\chris\\anaconda3\\lib\\site-packages (from jinja2->torch>=1.8.1->torchmetrics) (2.1.1)\n",
      "Requirement already satisfied: mpmath>=0.19 in c:\\users\\chris\\anaconda3\\lib\\site-packages (from sympy->torch>=1.8.1->torchmetrics) (1.3.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: lightning in c:\\users\\chris\\anaconda3\\lib\\site-packages (2.1.1)\n",
      "Requirement already satisfied: PyYAML<8.0,>=5.4 in c:\\users\\chris\\anaconda3\\lib\\site-packages (from lightning) (6.0.1)\n",
      "Requirement already satisfied: fsspec[http]<2025.0,>2021.06.0 in c:\\users\\chris\\anaconda3\\lib\\site-packages (from lightning) (2023.4.0)\n",
      "Requirement already satisfied: lightning-utilities<2.0,>=0.8.0 in c:\\users\\chris\\anaconda3\\lib\\site-packages (from lightning) (0.9.0)\n",
      "Requirement already satisfied: numpy<3.0,>=1.17.2 in c:\\users\\chris\\anaconda3\\lib\\site-packages (from lightning) (1.24.3)\n",
      "Requirement already satisfied: packaging<25.0,>=20.0 in c:\\users\\chris\\anaconda3\\lib\\site-packages (from lightning) (23.1)\n",
      "Requirement already satisfied: torch<4.0,>=1.12.0 in c:\\users\\chris\\anaconda3\\lib\\site-packages (from lightning) (2.1.1)\n",
      "Requirement already satisfied: torchmetrics<3.0,>=0.7.0 in c:\\users\\chris\\anaconda3\\lib\\site-packages (from lightning) (1.2.0)\n",
      "Requirement already satisfied: tqdm<6.0,>=4.57.0 in c:\\users\\chris\\anaconda3\\lib\\site-packages (from lightning) (4.65.0)\n",
      "Requirement already satisfied: typing-extensions<6.0,>=4.0.0 in c:\\users\\chris\\anaconda3\\lib\\site-packages (from lightning) (4.7.1)\n",
      "Requirement already satisfied: pytorch-lightning in c:\\users\\chris\\anaconda3\\lib\\site-packages (from lightning) (2.1.1)\n",
      "Requirement already satisfied: requests in c:\\users\\chris\\anaconda3\\lib\\site-packages (from fsspec[http]<2025.0,>2021.06.0->lightning) (2.31.0)\n",
      "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in c:\\users\\chris\\anaconda3\\lib\\site-packages (from fsspec[http]<2025.0,>2021.06.0->lightning) (3.8.5)\n",
      "Requirement already satisfied: filelock in c:\\users\\chris\\anaconda3\\lib\\site-packages (from torch<4.0,>=1.12.0->lightning) (3.9.0)\n",
      "Requirement already satisfied: sympy in c:\\users\\chris\\anaconda3\\lib\\site-packages (from torch<4.0,>=1.12.0->lightning) (1.11.1)\n",
      "Requirement already satisfied: networkx in c:\\users\\chris\\anaconda3\\lib\\site-packages (from torch<4.0,>=1.12.0->lightning) (3.1)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\chris\\anaconda3\\lib\\site-packages (from torch<4.0,>=1.12.0->lightning) (3.1.2)\n",
      "Requirement already satisfied: colorama in c:\\users\\chris\\anaconda3\\lib\\site-packages (from tqdm<6.0,>=4.57.0->lightning) (0.4.6)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\chris\\anaconda3\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2025.0,>2021.06.0->lightning) (23.1.0)\n",
      "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in c:\\users\\chris\\anaconda3\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2025.0,>2021.06.0->lightning) (2.0.4)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\chris\\anaconda3\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2025.0,>2021.06.0->lightning) (6.0.2)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in c:\\users\\chris\\anaconda3\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2025.0,>2021.06.0->lightning) (4.0.2)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in c:\\users\\chris\\anaconda3\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2025.0,>2021.06.0->lightning) (1.8.1)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\chris\\anaconda3\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2025.0,>2021.06.0->lightning) (1.4.0)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in c:\\users\\chris\\anaconda3\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2025.0,>2021.06.0->lightning) (1.2.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\chris\\anaconda3\\lib\\site-packages (from jinja2->torch<4.0,>=1.12.0->lightning) (2.1.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\chris\\anaconda3\\lib\\site-packages (from requests->fsspec[http]<2025.0,>2021.06.0->lightning) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\chris\\anaconda3\\lib\\site-packages (from requests->fsspec[http]<2025.0,>2021.06.0->lightning) (1.26.18)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\chris\\anaconda3\\lib\\site-packages (from requests->fsspec[http]<2025.0,>2021.06.0->lightning) (2023.7.22)\n",
      "Requirement already satisfied: mpmath>=0.19 in c:\\users\\chris\\anaconda3\\lib\\site-packages (from sympy->torch<4.0,>=1.12.0->lightning) (1.3.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\chris\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# general packages/libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from datetime import datetime # used to convert Date_time strings to useable format\n",
    "\n",
    "# torch\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from torch.utils.data import random_split\n",
    "\n",
    "# torchmetrics\n",
    "%pip install torchmetrics\n",
    "from torchmetrics import Accuracy\n",
    "\n",
    "# torchtext\n",
    "import torchtext.data\n",
    "from torchtext.vocab import build_vocab_from_iterator\n",
    "\n",
    "# lightning\n",
    "%pip install lightning\n",
    "from lightning.pytorch import LightningModule\n",
    "from lightning.pytorch import Trainer\n",
    "from lightning.pytorch.loggers import CSVLogger\n",
    "\n",
    "# tqdm\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "# nltk\n",
    "import nltk # used for tokenziation\n",
    "nltk.download('punkt')\n",
    "from nltk import word_tokenize\n",
    "\n",
    "# regular expressions\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Data Importing and Preprocessing:**\n",
    "This section is where the tweet data is imported and processed into tokens. This tokenization process is required so the neural network architectures can interpret the text data.\n",
    "\n",
    "**Tokenization definition:** the process of breaking down a sequence of information into smaller chunks known as tokens."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing the Dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Tweet ID</th>\n",
       "      <th>entity</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>Tweet content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2401</td>\n",
       "      <td>Borderlands</td>\n",
       "      <td>Positive</td>\n",
       "      <td>im getting on borderlands and i will murder yo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2401</td>\n",
       "      <td>Borderlands</td>\n",
       "      <td>Positive</td>\n",
       "      <td>I am coming to the borders and I will kill you...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2401</td>\n",
       "      <td>Borderlands</td>\n",
       "      <td>Positive</td>\n",
       "      <td>im getting on borderlands and i will kill you ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2401</td>\n",
       "      <td>Borderlands</td>\n",
       "      <td>Positive</td>\n",
       "      <td>im coming on borderlands and i will murder you...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2401</td>\n",
       "      <td>Borderlands</td>\n",
       "      <td>Positive</td>\n",
       "      <td>im getting on borderlands 2 and i will murder ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2401</td>\n",
       "      <td>Borderlands</td>\n",
       "      <td>Positive</td>\n",
       "      <td>im getting into borderlands and i can murder y...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2402</td>\n",
       "      <td>Borderlands</td>\n",
       "      <td>Positive</td>\n",
       "      <td>So I spent a few hours making something for fu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2402</td>\n",
       "      <td>Borderlands</td>\n",
       "      <td>Positive</td>\n",
       "      <td>So I spent a couple of hours doing something f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2402</td>\n",
       "      <td>Borderlands</td>\n",
       "      <td>Positive</td>\n",
       "      <td>So I spent a few hours doing something for fun...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2402</td>\n",
       "      <td>Borderlands</td>\n",
       "      <td>Positive</td>\n",
       "      <td>So I spent a few hours making something for fu...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Tweet ID       entity sentiment  \\\n",
       "0      2401  Borderlands  Positive   \n",
       "1      2401  Borderlands  Positive   \n",
       "2      2401  Borderlands  Positive   \n",
       "3      2401  Borderlands  Positive   \n",
       "4      2401  Borderlands  Positive   \n",
       "5      2401  Borderlands  Positive   \n",
       "6      2402  Borderlands  Positive   \n",
       "7      2402  Borderlands  Positive   \n",
       "8      2402  Borderlands  Positive   \n",
       "9      2402  Borderlands  Positive   \n",
       "\n",
       "                                       Tweet content  \n",
       "0  im getting on borderlands and i will murder yo...  \n",
       "1  I am coming to the borders and I will kill you...  \n",
       "2  im getting on borderlands and i will kill you ...  \n",
       "3  im coming on borderlands and i will murder you...  \n",
       "4  im getting on borderlands 2 and i will murder ...  \n",
       "5  im getting into borderlands and i can murder y...  \n",
       "6  So I spent a few hours making something for fu...  \n",
       "7  So I spent a couple of hours doing something f...  \n",
       "8  So I spent a few hours doing something for fun...  \n",
       "9  So I spent a few hours making something for fu...  "
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import the tweet data from the CSV using pandas\n",
    "tweet_data = pd.read_csv('./Datasets/twitter_training.csv', names=['Tweet ID', 'entity', 'sentiment', 'Tweet content'])\n",
    "tweet_data.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sentiment\n",
       "Negative    22542\n",
       "Positive    20832\n",
       "Neutral     18318\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# droppping \"irrelevant\" sentiment values\n",
    "tweet_data.drop(\n",
    "    tweet_data[tweet_data['sentiment'] == 'Irrelevant'].index,\n",
    "    inplace=True\n",
    ")\n",
    "\n",
    "# showing remaining sentiment distribution\n",
    "tweet_data['sentiment'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    0\n",
      "1    0\n",
      "2    0\n",
      "3    0\n",
      "4    0\n",
      "5    0\n",
      "6    0\n",
      "7    0\n",
      "8    0\n",
      "9    0\n",
      "Name: sentiment, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# extracting the the sentiment data for ease of use\n",
    "sentiment = tweet_data['sentiment']\n",
    "\n",
    "# the numerical representations of the sentiment values\n",
    "sentiment_numerical = {\n",
    "    'Positive': 0,\n",
    "    'Negative': 1,\n",
    "    'Neutral': 2,\n",
    "}\n",
    "\n",
    "# converting the sentiment data into a numerical form\n",
    "sentiment.replace(to_replace=sentiment_numerical, inplace=True)\n",
    "\n",
    "# showing the converted sentiment data\n",
    "print(sentiment.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    im getting on borderlands and i will murder yo...\n",
      "1    I am coming to the borders and I will kill you...\n",
      "2    im getting on borderlands and i will kill you ...\n",
      "3    im coming on borderlands and i will murder you...\n",
      "4    im getting on borderlands 2 and i will murder ...\n",
      "5    im getting into borderlands and i can murder y...\n",
      "6    So I spent a few hours making something for fu...\n",
      "7    So I spent a couple of hours doing something f...\n",
      "8    So I spent a few hours doing something for fun...\n",
      "9    So I spent a few hours making something for fu...\n",
      "Name: Tweet content, dtype: object\n"
     ]
    }
   ],
   "source": [
    "# extracting the the tweet content for ease of use\n",
    "content = tweet_data['Tweet content']\n",
    "\n",
    "# showing the extracted content\n",
    "print(content.head(10))\n",
    "\n",
    "# convert content to an iterator\n",
    "# content = iter(content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "method that processes content and removes the following content:\n",
    "- 1 word tweets\n",
    "- tweets that contain only special characters (e.g. /, ., <, etc.)\n",
    "'''\n",
    "def process_content(values:pd.Series, sentiments:pd.Series):\n",
    "    # convert series to list\n",
    "    values = values.to_list()\n",
    "    sentiments = sentiments.to_list()\n",
    "\n",
    "    # records the number of tweets removed\n",
    "    # (used to adjust the access index)\n",
    "    num_removed = 0\n",
    "\n",
    "    # #! DEBUG\n",
    "    # url_matches = 0\n",
    "\n",
    "    for i in tqdm(range(0, len(values))):\n",
    "        # checks for 1 word tweet using a tokenizer\n",
    "        if (len(word_tokenize(str(values[i - num_removed]))) <= 1):\n",
    "            # print('(1) ', i, ': ', str(values[i - num_removed]))  #! DEBUG\n",
    "            del values[i - num_removed]     # remove the tweet from the list\n",
    "            del sentiments[i - num_removed]      # remove the corresponding sentiment as well\n",
    "            num_removed += 1     # count the number of removed tweets\n",
    "\n",
    "        # checks for tweets with only \"...\", \" \", \"[\" or, \"]\"\n",
    "        # (only removes the tweet if the match is >=75% of the tweet content)\n",
    "        if (len(re.match(r'^(\\.|\\[|\\]| |\\n|[0-9])*', str(values[i - num_removed])).group(0)) >= int(len(str(values[i - num_removed]))*0.75)):\n",
    "            # print('(2) ', i, ': ', str(values[i - num_removed]))  #! DEBUG\n",
    "            del values[i - num_removed]     # remove the tweet from the list\n",
    "            del sentiments[i - num_removed]      # remove the corresponding sentiment as well\n",
    "            num_removed += 1     # count the number of removed tweets\n",
    "\n",
    "        url_match = re.match(r'(https?:\\ */\\ */\\ *)?(?:www\\.)?[a-zA-Z0-9.-]+\\.[a-zA-Z]{2,}(?:\\ */\\ *[^\\s]*)?', str(values[i - num_removed]))\n",
    "\n",
    "        # removes the tweets with links if a match exists\n",
    "        # if (url_match):\n",
    "        #     print('(3) ', i, ': ', url_match.group(0))  #! DEBUG\n",
    "        #     # del values[i - num_removed]     # remove the tweet from the list\n",
    "        #     # del sentiments[i - num_removed]      # remove the corresponding sentiment as well\n",
    "        #     # num_removed += 1     # count the number of removed tweets\n",
    "\n",
    "        #     #! DEBUG\n",
    "        #     url_matches += 1\n",
    "\n",
    "    # #! DEBUG\n",
    "    # print(url_matches)\n",
    "    return (pd.Series(values), pd.Series(sentiments))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3fb5de32742e4f2da77414d24dca97f8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/61692 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "0    im getting on borderlands and i will murder yo...\n",
       "1    I am coming to the borders and I will kill you...\n",
       "2    im getting on borderlands and i will kill you ...\n",
       "3    im coming on borderlands and i will murder you...\n",
       "4    im getting on borderlands 2 and i will murder ...\n",
       "5    im getting into borderlands and i can murder y...\n",
       "6    So I spent a few hours making something for fu...\n",
       "7    So I spent a couple of hours doing something f...\n",
       "8    So I spent a few hours doing something for fun...\n",
       "9    So I spent a few hours making something for fu...\n",
       "dtype: object"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "content, sentiment = process_content(content, sentiment)\n",
    "content.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "tags": [
     "hide_input"
    ]
   },
   "outputs": [],
   "source": [
    "# converting the sentiment data into a torch tensor\n",
    "sentiment = torch.tensor(sentiment, dtype=torch.int64)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tokenization:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f4f9f4b87ad94374ba458dbd39db2cc9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/59441 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "17481"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def iterate_tokens(df):\n",
    "    for val in tqdm(df):\n",
    "        yield word_tokenize(str(val))\n",
    "\n",
    "vocab = build_vocab_from_iterator(\n",
    "    iterate_tokens(content),\n",
    "    min_freq = 5,\n",
    "    specials = ['<unk>']\n",
    ") \n",
    "\n",
    "vocab.set_default_index(0)\n",
    "\n",
    "len(vocab)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Creating Data Loaders:**\n",
    "These data loaders are used by the models to access the tweet data. We will create two data loaders:\n",
    "* Training dataloader: used to train the models.\n",
    "* Validation dataloader: used to evaluate the performance of the models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "method that generates the training and validation dataloaders using the holdout method\n",
    "Takes three arguments:\n",
    "- data to create training and validation dataloaders with\n",
    "- the sentiment data\n",
    "- the vocabulary values\n",
    "- maximum tweet length (default is 250)\n",
    "- size of batches (default is 32)\n",
    "'''\n",
    "def create_dataloaders(data:pd.Series, sentiments:pd.Series, vocab, max_length = 250, batch_size = 32):\n",
    "    # create the sequences using the vocab\n",
    "    sequences = [\n",
    "        torch.tensor(\n",
    "            vocab.lookup_indices(word_tokenize(str(tweet))),\n",
    "            dtype = torch.int64\n",
    "        ) for tweet in tqdm(content)\n",
    "    ]\n",
    "\n",
    "    # create the padded sequences\n",
    "    padded_sequences = pad_sequence(sequences, batch_first=True)[:, :max_length]\n",
    "\n",
    "    # create the training and validation datasets used to create the dataloaders\n",
    "    (train_dataset, val_dataset) = random_split(TensorDataset(padded_sequences, sentiments), (0.7, 0.3))  # 70% train, 30% validation\n",
    "\n",
    "    # create the training and validation dataloaders\n",
    "    train_dataloader = DataLoader(train_dataset, shuffle=True, batch_size=batch_size)\n",
    "    val_dataloader = DataLoader(val_dataset, shuffle=False, batch_size=batch_size)\n",
    "\n",
    "    # return the training and validation dataloaders in a tuple\n",
    "    return (train_dataloader, val_dataloader)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1127b812412a41e2b345e0e500c04981",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/59441 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_dataloader, val_dataloader = create_dataloaders(content, sentiment, vocab)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Model Creation:**\n",
    "This is where the models being used are defined."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **RNN Model:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a basic RNN classifier using a LightningModule\n",
    "class RNN_classifier(LightningModule):\n",
    "    def __init__(self, vocab_size, embedding_dimension, state_dimension):\n",
    "        super().__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, embedding_dimension)\n",
    "        self.rnn = nn.RNN(\n",
    "            input_size = embedding_dimension,\n",
    "            hidden_size = state_dimension,\n",
    "            num_layers = 1, # hyperparameter\n",
    "            batch_first = True\n",
    "        )\n",
    "\n",
    "        # possible outputs: positive, negative, neutral\n",
    "        self.output = nn.Linear(state_dimension, 3)\n",
    "\n",
    "        # activation function to provide probabilities\n",
    "        self.activation = nn.Softmax(dim = 1)\n",
    "\n",
    "        # monitors accuracy\n",
    "        self.accuracy = Accuracy(task = 'multiclass', num_classes = 3)\n",
    "\n",
    "    def forward(self, sequence_batch):\n",
    "        embedded = self.embedding(sequence_batch)\n",
    "        h_t, h_n = self.rnn(embedded)  # output features (h_t) and state (h_n)\n",
    "        output = self.output(h_n[-1])\n",
    "        output = self.activation(output)\n",
    "\n",
    "        return output \n",
    "\n",
    "    def loss(self, output, targets):\n",
    "        loss = nn.CrossEntropyLoss()\n",
    "\n",
    "        return loss(output, targets)\n",
    "\n",
    "    def training_step(self, batch):\n",
    "        inputs, targets = batch\n",
    "        outputs = self.forward(inputs)\n",
    "        loss = self.loss(outputs, targets)\n",
    "\n",
    "        # get accuracy value\n",
    "        self.accuracy(outputs, targets)\n",
    "\n",
    "        # log the training accuracy\n",
    "        self.log('training accuracy', self.accuracy, prog_bar = True)\n",
    "\n",
    "        return loss\n",
    "\n",
    "    def validation_step(self, batch):\n",
    "        inputs, targets = batch\n",
    "        outputs = self.forward(inputs)\n",
    "\n",
    "        # get accuracy value\n",
    "        self.accuracy(outputs, targets)\n",
    "\n",
    "        # log the validation accuracy\n",
    "        self.log('validation accuracy', self.accuracy, prog_bar = True)\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        return torch.optim.Adam(self.parameters())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **GRU Model:**\n",
    "GRU stands for **G**ated **R**ecurrent **U**nit, and it is a type of Recurrent Neural Network that uses gating mechanisms to control the information flow in and out of the network. It is a simpler alternative to LSTM, which we will be covering next. (https://www.geeksforgeeks.org/gated-recurrent-unit-networks/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **LSTM Model:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# an LSTM classifier using a LightningModule\n",
    "class LSTM_classifier(LightningModule):\n",
    "    def __init__(self, vocab_size, embedding_dimension, state_dimension):\n",
    "        super().__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, embedding_dimension)\n",
    "        self.lstm = nn.LSTM(\n",
    "            input_size = embedding_dimension,\n",
    "            hidden_size = state_dimension,\n",
    "            num_layers = 1, # hyperparameter\n",
    "            batch_first = True\n",
    "        )\n",
    "\n",
    "        # possible outputs: positive, negative, neutral\n",
    "        self.output = nn.Linear(state_dimension, 3)\n",
    "\n",
    "        # activation function to provide probabilities\n",
    "        self.activation = nn.Softmax(dim = 1)\n",
    "\n",
    "        # monitors accuracy\n",
    "        self.accuracy = Accuracy(task = 'multiclass', num_classes = 3)\n",
    "\n",
    "    def forward(self, sequence_batch):\n",
    "        embedded = self.embedding(sequence_batch)\n",
    "        h_t, (h_n, _) = self.lstm(embedded)  # output features (h_t) and state (h_n)\n",
    "        output = self.output(h_n[-1])\n",
    "        output = self.activation(output)\n",
    "\n",
    "        return output\n",
    "\n",
    "    def loss(self, output, targets):\n",
    "        loss = nn.CrossEntropyLoss()\n",
    "\n",
    "        return loss(output, targets)\n",
    "\n",
    "    def training_step(self, batch):\n",
    "        inputs, targets = batch\n",
    "        outputs = self.forward(inputs)\n",
    "        loss = self.loss(outputs, targets)\n",
    "\n",
    "        # get accuracy value\n",
    "        self.accuracy(outputs, targets)\n",
    "\n",
    "        # log the training accuracy\n",
    "        self.log('training accuracy', self.accuracy, prog_bar = True)\n",
    "\n",
    "        return loss\n",
    "\n",
    "    def validation_step(self, batch):\n",
    "        inputs, targets = batch\n",
    "        outputs = self.forward(inputs)\n",
    "\n",
    "        # get accuracy value\n",
    "        self.accuracy(outputs, targets)\n",
    "\n",
    "        # log the validation accuracy\n",
    "        self.log('validation accuracy', self.accuracy, prog_bar = True)\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        return torch.optim.Adam(self.parameters())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Transformer Model:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Model Training:**\n",
    "This is where the models defined in the previous section are trained."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **RNN Model:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "  | Name       | Type               | Params\n",
      "--------------------------------------------------\n",
      "0 | embedding  | Embedding          | 559 K \n",
      "1 | rnn        | RNN                | 6.3 K \n",
      "2 | output     | Linear             | 195   \n",
      "3 | activation | Softmax            | 0     \n",
      "4 | accuracy   | MulticlassAccuracy | 0     \n",
      "--------------------------------------------------\n",
      "565 K     Trainable params\n",
      "0         Non-trainable params\n",
      "565 K     Total params\n",
      "2.263     Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "96112ec3bea042c4a2191f700c0f387f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\chris\\anaconda3\\Lib\\site-packages\\lightning\\pytorch\\trainer\\connectors\\data_connector.py:441: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=11` in the `DataLoader` to improve performance.\n",
      "c:\\Users\\chris\\anaconda3\\Lib\\site-packages\\lightning\\pytorch\\trainer\\connectors\\data_connector.py:441: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=11` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "53c81ed76b5840d18f6e55281bce0557",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\chris\\anaconda3\\Lib\\site-packages\\lightning\\pytorch\\trainer\\call.py:54: Detected KeyboardInterrupt, attempting graceful shutdown...\n"
     ]
    }
   ],
   "source": [
    "RNN_model = RNN_classifier(\n",
    "    vocab_size=len(vocab),\n",
    "    embedding_dimension = 32, # hyperparameter\n",
    "    state_dimension = 64 # hyperparameter\n",
    ")\n",
    "\n",
    "RNN_logger = CSVLogger('./lightning_logs/', 'RNN')\n",
    "trainer = Trainer(max_epochs = 10, logger = RNN_logger) # hyperparameter (# epochs)\n",
    "\n",
    "trainer.fit(\n",
    "    RNN_model,\n",
    "    train_dataloaders = train_dataloader,\n",
    "    val_dataloaders = val_dataloader\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **GRU Model:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **LSTM Model:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "  | Name       | Type               | Params\n",
      "--------------------------------------------------\n",
      "0 | embedding  | Embedding          | 559 K \n",
      "1 | lstm       | LSTM               | 25.1 K\n",
      "2 | output     | Linear             | 195   \n",
      "3 | activation | Softmax            | 0     \n",
      "4 | accuracy   | MulticlassAccuracy | 0     \n",
      "--------------------------------------------------\n",
      "584 K     Trainable params\n",
      "0         Non-trainable params\n",
      "584 K     Total params\n",
      "2.339     Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "767ba111cdb249a2bd96e70d2917ddb8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "501e19364c114baab401a66e9a4ce13f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "LSTM_model = LSTM_classifier(\n",
    "    vocab_size = len(vocab),\n",
    "    embedding_dimension = 32, # hyperparameter\n",
    "    state_dimension = 64 # hyperparameter\n",
    ")\n",
    "\n",
    "LSTM_logger = CSVLogger('./lightning_logs/', 'LSTM')\n",
    "trainer = Trainer(max_epochs = 10, logger = LSTM_logger) # hyperparameter (# epochs)\n",
    "\n",
    "trainer.fit(\n",
    "    LSTM_model,\n",
    "    train_dataloaders = train_dataloader,\n",
    "    val_dataloaders = val_dataloader\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Transformer Model:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Model Analysis & Comparison:**\n",
    "In this section, we will be analyzing the performance of each of the model types. We will compare their performance, and decide which is the best for sentiment analysis on this particular dataset. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **RNN Model:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
