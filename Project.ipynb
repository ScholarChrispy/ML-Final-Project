{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **ML Final Project**:\n",
    "\n",
    "### **Group Members:**\n",
    "- Christopher Johnson (christopher.johnson13@ontariotechu.net)\n",
    "- Name (Student Email)\n",
    "- Name (Student Email)\n",
    "- Name (Student Email)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Project Goals & Outline:**\n",
    "The goal of this project is to use sentiment analysis to analyze the content of tweets, and make decisions on whether their sentiment is positive, negative, or neutral.\n",
    "\n",
    "### Outline:\n",
    "1. Data Importing and Preprocessing\n",
    "2. Model Construction\n",
    "   1. RNN\n",
    "   2. LSTM\n",
    "   3. ???\n",
    "3. Model Training\n",
    "   1. RNN\n",
    "   2. LSTM\n",
    "   3. ???\n",
    "4. Model Analysis and Comparison\n",
    "5. Conclusions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Importing Packages & Libraries:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torchmetrics in c:\\users\\chris\\anaconda3\\lib\\site-packages (1.2.0)\n",
      "Requirement already satisfied: numpy>1.20.0 in c:\\users\\chris\\anaconda3\\lib\\site-packages (from torchmetrics) (1.24.3)\n",
      "Requirement already satisfied: torch>=1.8.1 in c:\\users\\chris\\anaconda3\\lib\\site-packages (from torchmetrics) (2.1.1)\n",
      "Requirement already satisfied: lightning-utilities>=0.8.0 in c:\\users\\chris\\anaconda3\\lib\\site-packages (from torchmetrics) (0.9.0)\n",
      "Requirement already satisfied: packaging>=17.1 in c:\\users\\chris\\anaconda3\\lib\\site-packages (from lightning-utilities>=0.8.0->torchmetrics) (23.1)\n",
      "Requirement already satisfied: typing-extensions in c:\\users\\chris\\anaconda3\\lib\\site-packages (from lightning-utilities>=0.8.0->torchmetrics) (4.7.1)\n",
      "Requirement already satisfied: filelock in c:\\users\\chris\\anaconda3\\lib\\site-packages (from torch>=1.8.1->torchmetrics) (3.9.0)\n",
      "Requirement already satisfied: sympy in c:\\users\\chris\\anaconda3\\lib\\site-packages (from torch>=1.8.1->torchmetrics) (1.11.1)\n",
      "Requirement already satisfied: networkx in c:\\users\\chris\\anaconda3\\lib\\site-packages (from torch>=1.8.1->torchmetrics) (3.1)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\chris\\anaconda3\\lib\\site-packages (from torch>=1.8.1->torchmetrics) (3.1.2)\n",
      "Requirement already satisfied: fsspec in c:\\users\\chris\\anaconda3\\lib\\site-packages (from torch>=1.8.1->torchmetrics) (2023.4.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\chris\\anaconda3\\lib\\site-packages (from jinja2->torch>=1.8.1->torchmetrics) (2.1.1)\n",
      "Requirement already satisfied: mpmath>=0.19 in c:\\users\\chris\\anaconda3\\lib\\site-packages (from sympy->torch>=1.8.1->torchmetrics) (1.3.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: lightning in c:\\users\\chris\\anaconda3\\lib\\site-packages (2.1.1)Note: you may need to restart the kernel to use updated packages.\n",
      "\n",
      "Requirement already satisfied: PyYAML<8.0,>=5.4 in c:\\users\\chris\\anaconda3\\lib\\site-packages (from lightning) (6.0.1)\n",
      "Requirement already satisfied: fsspec[http]<2025.0,>2021.06.0 in c:\\users\\chris\\anaconda3\\lib\\site-packages (from lightning) (2023.4.0)\n",
      "Requirement already satisfied: lightning-utilities<2.0,>=0.8.0 in c:\\users\\chris\\anaconda3\\lib\\site-packages (from lightning) (0.9.0)\n",
      "Requirement already satisfied: numpy<3.0,>=1.17.2 in c:\\users\\chris\\anaconda3\\lib\\site-packages (from lightning) (1.24.3)\n",
      "Requirement already satisfied: packaging<25.0,>=20.0 in c:\\users\\chris\\anaconda3\\lib\\site-packages (from lightning) (23.1)\n",
      "Requirement already satisfied: torch<4.0,>=1.12.0 in c:\\users\\chris\\anaconda3\\lib\\site-packages (from lightning) (2.1.1)\n",
      "Requirement already satisfied: torchmetrics<3.0,>=0.7.0 in c:\\users\\chris\\anaconda3\\lib\\site-packages (from lightning) (1.2.0)\n",
      "Requirement already satisfied: tqdm<6.0,>=4.57.0 in c:\\users\\chris\\anaconda3\\lib\\site-packages (from lightning) (4.65.0)\n",
      "Requirement already satisfied: typing-extensions<6.0,>=4.0.0 in c:\\users\\chris\\anaconda3\\lib\\site-packages (from lightning) (4.7.1)\n",
      "Requirement already satisfied: pytorch-lightning in c:\\users\\chris\\anaconda3\\lib\\site-packages (from lightning) (2.1.1)\n",
      "Requirement already satisfied: requests in c:\\users\\chris\\anaconda3\\lib\\site-packages (from fsspec[http]<2025.0,>2021.06.0->lightning) (2.31.0)\n",
      "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in c:\\users\\chris\\anaconda3\\lib\\site-packages (from fsspec[http]<2025.0,>2021.06.0->lightning) (3.8.5)\n",
      "Requirement already satisfied: filelock in c:\\users\\chris\\anaconda3\\lib\\site-packages (from torch<4.0,>=1.12.0->lightning) (3.9.0)\n",
      "Requirement already satisfied: sympy in c:\\users\\chris\\anaconda3\\lib\\site-packages (from torch<4.0,>=1.12.0->lightning) (1.11.1)\n",
      "Requirement already satisfied: networkx in c:\\users\\chris\\anaconda3\\lib\\site-packages (from torch<4.0,>=1.12.0->lightning) (3.1)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\chris\\anaconda3\\lib\\site-packages (from torch<4.0,>=1.12.0->lightning) (3.1.2)\n",
      "Requirement already satisfied: colorama in c:\\users\\chris\\anaconda3\\lib\\site-packages (from tqdm<6.0,>=4.57.0->lightning) (0.4.6)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\chris\\anaconda3\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2025.0,>2021.06.0->lightning) (23.1.0)\n",
      "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in c:\\users\\chris\\anaconda3\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2025.0,>2021.06.0->lightning) (2.0.4)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\chris\\anaconda3\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2025.0,>2021.06.0->lightning) (6.0.2)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in c:\\users\\chris\\anaconda3\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2025.0,>2021.06.0->lightning) (4.0.2)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in c:\\users\\chris\\anaconda3\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2025.0,>2021.06.0->lightning) (1.8.1)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\chris\\anaconda3\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2025.0,>2021.06.0->lightning) (1.4.0)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in c:\\users\\chris\\anaconda3\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2025.0,>2021.06.0->lightning) (1.2.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\chris\\anaconda3\\lib\\site-packages (from jinja2->torch<4.0,>=1.12.0->lightning) (2.1.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\chris\\anaconda3\\lib\\site-packages (from requests->fsspec[http]<2025.0,>2021.06.0->lightning) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\chris\\anaconda3\\lib\\site-packages (from requests->fsspec[http]<2025.0,>2021.06.0->lightning) (1.26.18)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\chris\\anaconda3\\lib\\site-packages (from requests->fsspec[http]<2025.0,>2021.06.0->lightning) (2023.7.22)\n",
      "Requirement already satisfied: mpmath>=0.19 in c:\\users\\chris\\anaconda3\\lib\\site-packages (from sympy->torch<4.0,>=1.12.0->lightning) (1.3.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\chris\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# general packages/libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from datetime import datetime # used to convert Date_time strings to useable format\n",
    "\n",
    "# torch\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from torch.utils.data import random_split\n",
    "\n",
    "# torchmetrics\n",
    "%pip install torchmetrics\n",
    "from torchmetrics import Accuracy\n",
    "\n",
    "# torchtext\n",
    "import torchtext.data\n",
    "from torchtext.vocab import build_vocab_from_iterator\n",
    "\n",
    "# lightning\n",
    "%pip install lightning\n",
    "from lightning.pytorch import LightningModule\n",
    "from lightning.pytorch import Trainer\n",
    "from lightning.pytorch.loggers import CSVLogger\n",
    "\n",
    "# tqdm\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "# nltk\n",
    "import nltk # used for tokenziation\n",
    "nltk.download('punkt')\n",
    "from nltk import word_tokenize\n",
    "\n",
    "# regular expressions\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Data Importing and Preprocessing:**\n",
    "This section is where the tweet data is imported and processed into tokens. This tokenization process is required so the neural network architectures can interpret the text data.\n",
    "\n",
    "**Tokenization definition:** the process of breaking down a sequence of information into smaller chunks known as tokens."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing the Dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Tweet ID</th>\n",
       "      <th>entity</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>Tweet content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2401</td>\n",
       "      <td>Borderlands</td>\n",
       "      <td>Positive</td>\n",
       "      <td>im getting on borderlands and i will murder yo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2401</td>\n",
       "      <td>Borderlands</td>\n",
       "      <td>Positive</td>\n",
       "      <td>I am coming to the borders and I will kill you...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2401</td>\n",
       "      <td>Borderlands</td>\n",
       "      <td>Positive</td>\n",
       "      <td>im getting on borderlands and i will kill you ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2401</td>\n",
       "      <td>Borderlands</td>\n",
       "      <td>Positive</td>\n",
       "      <td>im coming on borderlands and i will murder you...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2401</td>\n",
       "      <td>Borderlands</td>\n",
       "      <td>Positive</td>\n",
       "      <td>im getting on borderlands 2 and i will murder ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2401</td>\n",
       "      <td>Borderlands</td>\n",
       "      <td>Positive</td>\n",
       "      <td>im getting into borderlands and i can murder y...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2402</td>\n",
       "      <td>Borderlands</td>\n",
       "      <td>Positive</td>\n",
       "      <td>So I spent a few hours making something for fu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2402</td>\n",
       "      <td>Borderlands</td>\n",
       "      <td>Positive</td>\n",
       "      <td>So I spent a couple of hours doing something f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2402</td>\n",
       "      <td>Borderlands</td>\n",
       "      <td>Positive</td>\n",
       "      <td>So I spent a few hours doing something for fun...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2402</td>\n",
       "      <td>Borderlands</td>\n",
       "      <td>Positive</td>\n",
       "      <td>So I spent a few hours making something for fu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2402</td>\n",
       "      <td>Borderlands</td>\n",
       "      <td>Positive</td>\n",
       "      <td>2010 So I spent a few hours making something f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>2402</td>\n",
       "      <td>Borderlands</td>\n",
       "      <td>Positive</td>\n",
       "      <td>was</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>2403</td>\n",
       "      <td>Borderlands</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>Rock-Hard La Varlope, RARE &amp; POWERFUL, HANDSOM...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>2403</td>\n",
       "      <td>Borderlands</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>Rock-Hard La Varlope, RARE &amp; POWERFUL, HANDSOM...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>2403</td>\n",
       "      <td>Borderlands</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>Rock-Hard La Varlope, RARE &amp; POWERFUL, HANDSOM...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>2403</td>\n",
       "      <td>Borderlands</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>Rock-Hard La Vita, RARE BUT POWERFUL, HANDSOME...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>2403</td>\n",
       "      <td>Borderlands</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>Live Rock - Hard music La la Varlope, RARE &amp; t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>2403</td>\n",
       "      <td>Borderlands</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>I-Hard like me, RARE LONDON DE, HANDSOME 2011,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>2404</td>\n",
       "      <td>Borderlands</td>\n",
       "      <td>Positive</td>\n",
       "      <td>that was the first borderlands session in a lo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>2404</td>\n",
       "      <td>Borderlands</td>\n",
       "      <td>Positive</td>\n",
       "      <td>this was the first Borderlands session in a lo...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Tweet ID       entity sentiment  \\\n",
       "0       2401  Borderlands  Positive   \n",
       "1       2401  Borderlands  Positive   \n",
       "2       2401  Borderlands  Positive   \n",
       "3       2401  Borderlands  Positive   \n",
       "4       2401  Borderlands  Positive   \n",
       "5       2401  Borderlands  Positive   \n",
       "6       2402  Borderlands  Positive   \n",
       "7       2402  Borderlands  Positive   \n",
       "8       2402  Borderlands  Positive   \n",
       "9       2402  Borderlands  Positive   \n",
       "10      2402  Borderlands  Positive   \n",
       "11      2402  Borderlands  Positive   \n",
       "12      2403  Borderlands   Neutral   \n",
       "13      2403  Borderlands   Neutral   \n",
       "14      2403  Borderlands   Neutral   \n",
       "15      2403  Borderlands   Neutral   \n",
       "16      2403  Borderlands   Neutral   \n",
       "17      2403  Borderlands   Neutral   \n",
       "18      2404  Borderlands  Positive   \n",
       "19      2404  Borderlands  Positive   \n",
       "\n",
       "                                        Tweet content  \n",
       "0   im getting on borderlands and i will murder yo...  \n",
       "1   I am coming to the borders and I will kill you...  \n",
       "2   im getting on borderlands and i will kill you ...  \n",
       "3   im coming on borderlands and i will murder you...  \n",
       "4   im getting on borderlands 2 and i will murder ...  \n",
       "5   im getting into borderlands and i can murder y...  \n",
       "6   So I spent a few hours making something for fu...  \n",
       "7   So I spent a couple of hours doing something f...  \n",
       "8   So I spent a few hours doing something for fun...  \n",
       "9   So I spent a few hours making something for fu...  \n",
       "10  2010 So I spent a few hours making something f...  \n",
       "11                                                was  \n",
       "12  Rock-Hard La Varlope, RARE & POWERFUL, HANDSOM...  \n",
       "13  Rock-Hard La Varlope, RARE & POWERFUL, HANDSOM...  \n",
       "14  Rock-Hard La Varlope, RARE & POWERFUL, HANDSOM...  \n",
       "15  Rock-Hard La Vita, RARE BUT POWERFUL, HANDSOME...  \n",
       "16  Live Rock - Hard music La la Varlope, RARE & t...  \n",
       "17  I-Hard like me, RARE LONDON DE, HANDSOME 2011,...  \n",
       "18  that was the first borderlands session in a lo...  \n",
       "19  this was the first Borderlands session in a lo...  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import the tweet data from the CSV using pandas\n",
    "tweet_data = pd.read_csv('./Datasets/twitter_training.csv', names=['Tweet ID', 'entity', 'sentiment', 'Tweet content'])\n",
    "tweet_data.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sentiment\n",
       "Negative    22542\n",
       "Positive    20832\n",
       "Neutral     18318\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# droppping \"irrelevant\" sentiment values\n",
    "tweet_data.drop(\n",
    "    tweet_data[tweet_data['sentiment'] == 'Irrelevant'].index,\n",
    "    inplace=True\n",
    ")\n",
    "\n",
    "# showing remaining sentiment distribution\n",
    "tweet_data['sentiment'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0     0\n",
      "1     0\n",
      "2     0\n",
      "3     0\n",
      "4     0\n",
      "5     0\n",
      "6     0\n",
      "7     0\n",
      "8     0\n",
      "9     0\n",
      "10    0\n",
      "11    0\n",
      "12    2\n",
      "13    2\n",
      "14    2\n",
      "15    2\n",
      "16    2\n",
      "17    2\n",
      "18    0\n",
      "19    0\n",
      "Name: sentiment, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# extracting the the sentiment data for ease of use\n",
    "sentiment = tweet_data['sentiment']\n",
    "\n",
    "# the numerical representations of the sentiment values\n",
    "sentiment_numerical = {\n",
    "    'Positive': 0,\n",
    "    'Negative': 1,\n",
    "    'Neutral': 2,\n",
    "}\n",
    "\n",
    "# converting the sentiment data into a numerical form\n",
    "sentiment.replace(to_replace=sentiment_numerical, inplace=True)\n",
    "\n",
    "# showing the converted sentiment data\n",
    "print(sentiment.head(20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0     im getting on borderlands and i will murder yo...\n",
      "1     I am coming to the borders and I will kill you...\n",
      "2     im getting on borderlands and i will kill you ...\n",
      "3     im coming on borderlands and i will murder you...\n",
      "4     im getting on borderlands 2 and i will murder ...\n",
      "5     im getting into borderlands and i can murder y...\n",
      "6     So I spent a few hours making something for fu...\n",
      "7     So I spent a couple of hours doing something f...\n",
      "8     So I spent a few hours doing something for fun...\n",
      "9     So I spent a few hours making something for fu...\n",
      "10    2010 So I spent a few hours making something f...\n",
      "11                                                  was\n",
      "12    Rock-Hard La Varlope, RARE & POWERFUL, HANDSOM...\n",
      "13    Rock-Hard La Varlope, RARE & POWERFUL, HANDSOM...\n",
      "14    Rock-Hard La Varlope, RARE & POWERFUL, HANDSOM...\n",
      "15    Rock-Hard La Vita, RARE BUT POWERFUL, HANDSOME...\n",
      "16    Live Rock - Hard music La la Varlope, RARE & t...\n",
      "17    I-Hard like me, RARE LONDON DE, HANDSOME 2011,...\n",
      "18    that was the first borderlands session in a lo...\n",
      "19    this was the first Borderlands session in a lo...\n",
      "20    that was the first borderlands session in a lo...\n",
      "21    that was the first borderlands session in a lo...\n",
      "22    that I was the first real borderlands session ...\n",
      "23    that was the first borderlands session in a ho...\n",
      "24    the biggest dissappoinment in my life came out...\n",
      "25    The biggest disappointment of my life came a y...\n",
      "26    The biggest disappointment of my life came a y...\n",
      "27    the biggest dissappoinment in my life coming o...\n",
      "28    For the biggest male dissappoinment in my life...\n",
      "29    the biggest dissappoinment in my life came bac...\n",
      "30    WE FINISHED BORDERLANDS 3 FINALLY YAS! Thank y...\n",
      "31    WE FINALLY FINALLY FIND BORDERLANDS 3 YES! Tha...\n",
      "32    Thank you for hanging up everyone! It was fun....\n",
      "33    WE FINISHED BORDERLANDS 3 UPDATE YAS! Thank yo...\n",
      "34    WE FINISHED BORDERLANDS 3 AND FINALLY YAS! Tha...\n",
      "35    WE FINISHED BORDERLANDS 3 FINALLY YAS! Hey you...\n",
      "36    Man Gearbox really needs to fix this dissapoin...\n",
      "37    Man Gearbox really needs to fix these disappoi...\n",
      "38    Man Gearbox really needs to fix this disssapoi...\n",
      "39    Man Bethesda really needs to fix this dissapoi...\n",
      "40    Man Gearbox really needs to fix this dissapoin...\n",
      "41    <unk> Gearbox really time to fix this 10 drops...\n",
      "42                     Check out this epic streamer!.  \n",
      "43                       Check out this epic streamer!.\n",
      "44                         Watch this epic striptease!.\n",
      "45                        Check out our epic streamer!.\n",
      "46                   Check out this big epic streamer!.\n",
      "47                      Check<unk> this epic streamer!.\n",
      "48    Blaming Sight for Tardiness! A little bit of b...\n",
      "49    A bit of borderland. I was called to work tomo...\n",
      "50    Guilty of sobriety! A bit of a borderline. I w...\n",
      "51    Blaming Sight for Tardiness! A little bit of b...\n",
      "52    for Blaming Sight for Tardiness! A little bit ...\n",
      "53                                                  all\n",
      "54    why does like every man in borderlands have sl...\n",
      "55    Why, like every man in border countries, have ...\n",
      "56    Why, like everyone else in the border countrie...\n",
      "57    why does like<unk> man in borderlands have sli...\n",
      "58    why Beth does like every man in borderlands ha...\n",
      "59    why does practically every man in France have ...\n",
      "Name: Tweet content, dtype: object\n"
     ]
    }
   ],
   "source": [
    "# extracting the the tweet content for ease of use\n",
    "content = tweet_data['Tweet content']\n",
    "\n",
    "# showing the extracted content\n",
    "print(content.head(60))\n",
    "\n",
    "# convert content to an iterator\n",
    "# content = iter(content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "method that processes content and removes the following content:\n",
    "- 1 word tweets\n",
    "- tweets that contain only special characters (e.g. /, ., <, etc.)\n",
    "'''\n",
    "def process_content(values:pd.Series, sentiments:pd.Series):\n",
    "    # convert series to list\n",
    "    values = values.to_list()\n",
    "    sentiments = sentiments.to_list()\n",
    "\n",
    "    # records the number of tweets removed\n",
    "    # (used to adjust the access index)\n",
    "    num_removed = 0\n",
    "\n",
    "    # #! DEBUG\n",
    "    # url_matches = 0\n",
    "\n",
    "    for i in tqdm(range(0, len(values))):\n",
    "        # checks for 1 word tweet using a tokenizer\n",
    "        if (len(word_tokenize(str(values[i - num_removed]))) <= 1):\n",
    "            # print('(1) ', i, ': ', str(values[i - num_removed]))  #! DEBUG\n",
    "            del values[i - num_removed]     # remove the tweet from the list\n",
    "            del sentiments[i - num_removed]      # remove the corresponding sentiment as well\n",
    "            num_removed += 1     # count the number of removed tweets\n",
    "\n",
    "        # checks for tweets with only \"...\", \" \", \"[\" or, \"]\"\n",
    "        # (only removes the tweet if the match is >=75% of the tweet content)\n",
    "        if (len(re.match(r'^(\\.|\\[|\\]| |\\n|[0-9])*', str(values[i - num_removed])).group(0)) >= int(len(str(values[i - num_removed]))*0.75)):\n",
    "            # print('(2) ', i, ': ', str(values[i - num_removed]))  #! DEBUG\n",
    "            del values[i - num_removed]     # remove the tweet from the list\n",
    "            del sentiments[i - num_removed]      # remove the corresponding sentiment as well\n",
    "            num_removed += 1     # count the number of removed tweets\n",
    "\n",
    "        url_match = re.match(r'(https?:\\ */\\ */\\ *)?(?:www\\.)?[a-zA-Z0-9.-]+\\.[a-zA-Z]{2,}(?:\\ */\\ *[^\\s]*)?', str(values[i - num_removed]))\n",
    "\n",
    "        # removes the tweets with links if a match exists\n",
    "        # if (url_match):\n",
    "        #     print('(3) ', i, ': ', url_match.group(0))  #! DEBUG\n",
    "        #     # del values[i - num_removed]     # remove the tweet from the list\n",
    "        #     # del sentiments[i - num_removed]      # remove the corresponding sentiment as well\n",
    "        #     # num_removed += 1     # count the number of removed tweets\n",
    "\n",
    "        #     #! DEBUG\n",
    "        #     url_matches += 1\n",
    "\n",
    "    # #! DEBUG\n",
    "    # print(url_matches)\n",
    "    return (pd.Series(values), pd.Series(sentiments))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8dd5bacffe424c209bf88634261abc24",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/61692 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "0     im getting on borderlands and i will murder yo...\n",
       "1     I am coming to the borders and I will kill you...\n",
       "2     im getting on borderlands and i will kill you ...\n",
       "3     im coming on borderlands and i will murder you...\n",
       "4     im getting on borderlands 2 and i will murder ...\n",
       "5     im getting into borderlands and i can murder y...\n",
       "6     So I spent a few hours making something for fu...\n",
       "7     So I spent a couple of hours doing something f...\n",
       "8     So I spent a few hours doing something for fun...\n",
       "9     So I spent a few hours making something for fu...\n",
       "10    2010 So I spent a few hours making something f...\n",
       "11    Rock-Hard La Varlope, RARE & POWERFUL, HANDSOM...\n",
       "12    Rock-Hard La Varlope, RARE & POWERFUL, HANDSOM...\n",
       "13    Rock-Hard La Varlope, RARE & POWERFUL, HANDSOM...\n",
       "14    Rock-Hard La Vita, RARE BUT POWERFUL, HANDSOME...\n",
       "15    Live Rock - Hard music La la Varlope, RARE & t...\n",
       "16    I-Hard like me, RARE LONDON DE, HANDSOME 2011,...\n",
       "17    that was the first borderlands session in a lo...\n",
       "18    this was the first Borderlands session in a lo...\n",
       "19    that was the first borderlands session in a lo...\n",
       "dtype: object"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "content, sentiment = process_content(content, sentiment)\n",
    "content.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# converting the sentiment data into a torch tensor\n",
    "sentiment = torch.tensor(sentiment, dtype=torch.int64)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tokenization:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a50c56b74f7d45f188bc68e10c8f0177",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/59441 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "17481"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def iterate_tokens(df):\n",
    "    for val in tqdm(df):\n",
    "        yield word_tokenize(str(val))\n",
    "\n",
    "vocab = build_vocab_from_iterator(\n",
    "    iterate_tokens(content),\n",
    "    min_freq = 5,\n",
    "    specials = ['<unk>']\n",
    ") \n",
    "\n",
    "vocab.set_default_index(0)\n",
    "\n",
    "len(vocab)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Creating Data Loaders:**\n",
    "These data loaders are used by the models to access the tweet data. We will create two data loaders:\n",
    "* Training dataloader: used to train the models.\n",
    "* Validation dataloader: used to evaluate the performance of the models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "method that generates the training and validation dataloaders using the holdout method\n",
    "Takes three arguments:\n",
    "- data to create training and validation dataloaders with\n",
    "- the sentiment data\n",
    "- the vocabulary values\n",
    "- maximum tweet length (default is 250)\n",
    "- size of batches (default is 32)\n",
    "'''\n",
    "def create_dataloaders(data:pd.Series, sentiments:pd.Series, vocab, max_length = 250, batch_size = 32):\n",
    "    # create the sequences using the vocab\n",
    "    sequences = [\n",
    "        torch.tensor(\n",
    "            vocab.lookup_indices(word_tokenize(str(tweet))),\n",
    "            dtype = torch.int64\n",
    "        ) for tweet in tqdm(content)\n",
    "    ]\n",
    "\n",
    "    # create the padded sequences\n",
    "    padded_sequences = pad_sequence(sequences, batch_first=True)[:, :max_length]\n",
    "\n",
    "    # create the training and validation datasets used to create the dataloaders\n",
    "    (train_dataset, val_dataset) = random_split(TensorDataset(padded_sequences, sentiments), (0.7, 0.3))  # 70% train, 30% validation\n",
    "\n",
    "    # create the training and validation dataloaders\n",
    "    train_dataloader = DataLoader(train_dataset, shuffle=True, batch_size=batch_size)\n",
    "    val_dataloader = DataLoader(val_dataset, shuffle=False, batch_size=batch_size)\n",
    "\n",
    "    # return the training and validation dataloaders in a tuple\n",
    "    return (train_dataloader, val_dataloader)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c89bef72a9b940ba83421b2182edb062",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/59441 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_dataloader, val_dataloader = create_dataloaders(content, sentiment, vocab)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Model Creation:**\n",
    "This is where the models being used are defined."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **LSTM Model:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# an LSTM classifier using a LightningModule\n",
    "class LSTM_classifier(LightningModule):\n",
    "    def __init__(self, vocab_size, embedding_dimension, state_dimension):\n",
    "        super().__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, embedding_dimension)\n",
    "        self.lstm = nn.LSTM(\n",
    "            input_size = embedding_dimension,\n",
    "            hidden_size = state_dimension,\n",
    "            num_layers = 1, # hyperparameter\n",
    "            batch_first = True\n",
    "        )\n",
    "\n",
    "        # possible outputs: positive, negative, neutral\n",
    "        self.output = nn.Linear(state_dimension, 3)\n",
    "\n",
    "        # monitors accuracy\n",
    "        self.accuracy = Accuracy(task = 'multiclass', num_classes = 3)\n",
    "\n",
    "    def forward(self, sequence_batch):\n",
    "        embedded = self.embedding(sequence_batch)\n",
    "        h_t, h_n = self.lstm(embedded)  # output features (h_t) and state (h_n)\n",
    "        output = self.output(h_n[-1])\n",
    "\n",
    "        return output\n",
    "\n",
    "    def loss(self, output, targets):\n",
    "        loss = nn.CrossEntropyLoss()\n",
    "\n",
    "        return loss(output, targets)\n",
    "\n",
    "    def training_step(self, batch):\n",
    "        inputs, targets = batch\n",
    "        outputs = self.forward(inputs)\n",
    "        loss = self.loss(outputs, targets)\n",
    "\n",
    "        # get accuracy value\n",
    "        self.accuracy(outputs, targets)\n",
    "\n",
    "        # log the training accuracy\n",
    "        self.log('training accuracy', self.accuracy, prog_bar = True)\n",
    "\n",
    "        return loss\n",
    "\n",
    "    def validation_step(self, batch):\n",
    "        inputs, targets = batch\n",
    "        outputs = self.forward(inputs)\n",
    "\n",
    "        # get accuracy value\n",
    "        self.accuracy(outputs, targets)\n",
    "\n",
    "        # log the validation accuracy\n",
    "        self.log('validation accuracy', self.accuracy, prog_bar = True)\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        return torch.optim.Adam(self.parameters())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **RNN Model:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a basic RNN classifier using a LightningModule\n",
    "class RNN_classifier(LightningModule):\n",
    "    def __init__(self, vocab_size, embedding_dimension, state_dimension):\n",
    "        super().__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, embedding_dimension)\n",
    "        self.rnn = nn.RNN(\n",
    "            input_size = embedding_dimension,\n",
    "            hidden_size = state_dimension,\n",
    "            num_layers = 1, # hyperparameter\n",
    "            batch_first = True\n",
    "        )\n",
    "\n",
    "        # possible outputs: positive, negative, neutral\n",
    "        self.output = nn.Linear(state_dimension, 3)\n",
    "\n",
    "        # monitors accuracy\n",
    "        self.accuracy = Accuracy(task = 'multiclass', num_classes = 3)\n",
    "\n",
    "    def forward(self, sequence_batch):\n",
    "        embedded = self.embedding(sequence_batch)\n",
    "        h_t, h_n = self.rnn(embedded)  # output features (h_t) and state (h_n)\n",
    "        output = self.output(h_n[-1])\n",
    "\n",
    "        return output\n",
    "\n",
    "    def loss(self, output, targets):\n",
    "        loss = nn.CrossEntropyLoss()\n",
    "\n",
    "        return loss(output, targets)\n",
    "\n",
    "    def training_step(self, batch):\n",
    "        inputs, targets = batch\n",
    "        outputs = self.forward(inputs)\n",
    "        loss = self.loss(outputs, targets)\n",
    "\n",
    "        # get accuracy value\n",
    "        self.accuracy(outputs, targets)\n",
    "\n",
    "        # log the training accuracy\n",
    "        self.log('training accuracy', self.accuracy, prog_bar = True)\n",
    "\n",
    "        return loss\n",
    "\n",
    "    def validation_step(self, batch):\n",
    "        inputs, targets = batch\n",
    "        outputs = self.forward(inputs)\n",
    "\n",
    "        # get accuracy value\n",
    "        self.accuracy(outputs, targets)\n",
    "\n",
    "        # log the validation accuracy\n",
    "        self.log('validation accuracy', self.accuracy, prog_bar = True)\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        return torch.optim.Adam(self.parameters())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Model Training:**\n",
    "This is where the models defined in the previous section are trained."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **LSTM Model:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Missing logger folder: ./lightning_logs/LSTM\n",
      "\n",
      "  | Name      | Type               | Params\n",
      "-------------------------------------------------\n",
      "0 | embedding | Embedding          | 559 K \n",
      "1 | lstm      | LSTM               | 25.1 K\n",
      "2 | output    | Linear             | 195   \n",
      "3 | accuracy  | MulticlassAccuracy | 0     \n",
      "-------------------------------------------------\n",
      "584 K     Trainable params\n",
      "0         Non-trainable params\n",
      "584 K     Total params\n",
      "2.339     Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c95e6e7c0aaa47b39b43e33f9015c067",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\chris\\anaconda3\\Lib\\site-packages\\lightning\\pytorch\\trainer\\connectors\\data_connector.py:441: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=11` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Either `preds` and `target` both should have the (same) shape (N, ...), or `target` should be (N, ...) and `preds` should be (N, C, ...).",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\chris\\OneDrive\\Code\\OntarioTechCode\\(4) Year Four\\Semester One\\Machine Learning\\Final Project\\ML-Final-Project\\Project.ipynb Cell 26\u001b[0m line \u001b[0;36m1\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/chris/OneDrive/Code/OntarioTechCode/%284%29%20Year%20Four/Semester%20One/Machine%20Learning/Final%20Project/ML-Final-Project/Project.ipynb#X34sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m LSTM_logger \u001b[39m=\u001b[39m CSVLogger(\u001b[39m'\u001b[39m\u001b[39m./lightning_logs/\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mLSTM\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/chris/OneDrive/Code/OntarioTechCode/%284%29%20Year%20Four/Semester%20One/Machine%20Learning/Final%20Project/ML-Final-Project/Project.ipynb#X34sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m trainer \u001b[39m=\u001b[39m Trainer(max_epochs \u001b[39m=\u001b[39m \u001b[39m10\u001b[39m, logger \u001b[39m=\u001b[39m LSTM_logger) \u001b[39m# hyperparameter (# epochs)\u001b[39;00m\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/chris/OneDrive/Code/OntarioTechCode/%284%29%20Year%20Four/Semester%20One/Machine%20Learning/Final%20Project/ML-Final-Project/Project.ipynb#X34sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m trainer\u001b[39m.\u001b[39mfit(\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/chris/OneDrive/Code/OntarioTechCode/%284%29%20Year%20Four/Semester%20One/Machine%20Learning/Final%20Project/ML-Final-Project/Project.ipynb#X34sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m     LSTM_model,\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/chris/OneDrive/Code/OntarioTechCode/%284%29%20Year%20Four/Semester%20One/Machine%20Learning/Final%20Project/ML-Final-Project/Project.ipynb#X34sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m     train_dataloaders \u001b[39m=\u001b[39m train_dataloader,\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/chris/OneDrive/Code/OntarioTechCode/%284%29%20Year%20Four/Semester%20One/Machine%20Learning/Final%20Project/ML-Final-Project/Project.ipynb#X34sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m     val_dataloaders \u001b[39m=\u001b[39m val_dataloader\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/chris/OneDrive/Code/OntarioTechCode/%284%29%20Year%20Four/Semester%20One/Machine%20Learning/Final%20Project/ML-Final-Project/Project.ipynb#X34sZmlsZQ%3D%3D?line=13'>14</a>\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\chris\\anaconda3\\Lib\\site-packages\\lightning\\pytorch\\trainer\\trainer.py:544\u001b[0m, in \u001b[0;36mTrainer.fit\u001b[1;34m(self, model, train_dataloaders, val_dataloaders, datamodule, ckpt_path)\u001b[0m\n\u001b[0;32m    542\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstate\u001b[39m.\u001b[39mstatus \u001b[39m=\u001b[39m TrainerStatus\u001b[39m.\u001b[39mRUNNING\n\u001b[0;32m    543\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtraining \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[1;32m--> 544\u001b[0m call\u001b[39m.\u001b[39m_call_and_handle_interrupt(\n\u001b[0;32m    545\u001b[0m     \u001b[39mself\u001b[39m, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_fit_impl, model, train_dataloaders, val_dataloaders, datamodule, ckpt_path\n\u001b[0;32m    546\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\chris\\anaconda3\\Lib\\site-packages\\lightning\\pytorch\\trainer\\call.py:44\u001b[0m, in \u001b[0;36m_call_and_handle_interrupt\u001b[1;34m(trainer, trainer_fn, *args, **kwargs)\u001b[0m\n\u001b[0;32m     42\u001b[0m     \u001b[39mif\u001b[39;00m trainer\u001b[39m.\u001b[39mstrategy\u001b[39m.\u001b[39mlauncher \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m     43\u001b[0m         \u001b[39mreturn\u001b[39;00m trainer\u001b[39m.\u001b[39mstrategy\u001b[39m.\u001b[39mlauncher\u001b[39m.\u001b[39mlaunch(trainer_fn, \u001b[39m*\u001b[39margs, trainer\u001b[39m=\u001b[39mtrainer, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[1;32m---> 44\u001b[0m     \u001b[39mreturn\u001b[39;00m trainer_fn(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m     46\u001b[0m \u001b[39mexcept\u001b[39;00m _TunerExitException:\n\u001b[0;32m     47\u001b[0m     _call_teardown_hook(trainer)\n",
      "File \u001b[1;32mc:\\Users\\chris\\anaconda3\\Lib\\site-packages\\lightning\\pytorch\\trainer\\trainer.py:580\u001b[0m, in \u001b[0;36mTrainer._fit_impl\u001b[1;34m(self, model, train_dataloaders, val_dataloaders, datamodule, ckpt_path)\u001b[0m\n\u001b[0;32m    573\u001b[0m \u001b[39massert\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstate\u001b[39m.\u001b[39mfn \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m    574\u001b[0m ckpt_path \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_checkpoint_connector\u001b[39m.\u001b[39m_select_ckpt_path(\n\u001b[0;32m    575\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstate\u001b[39m.\u001b[39mfn,\n\u001b[0;32m    576\u001b[0m     ckpt_path,\n\u001b[0;32m    577\u001b[0m     model_provided\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m,\n\u001b[0;32m    578\u001b[0m     model_connected\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlightning_module \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m,\n\u001b[0;32m    579\u001b[0m )\n\u001b[1;32m--> 580\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_run(model, ckpt_path\u001b[39m=\u001b[39mckpt_path)\n\u001b[0;32m    582\u001b[0m \u001b[39massert\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstate\u001b[39m.\u001b[39mstopped\n\u001b[0;32m    583\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtraining \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\chris\\anaconda3\\Lib\\site-packages\\lightning\\pytorch\\trainer\\trainer.py:989\u001b[0m, in \u001b[0;36mTrainer._run\u001b[1;34m(self, model, ckpt_path)\u001b[0m\n\u001b[0;32m    984\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_signal_connector\u001b[39m.\u001b[39mregister_signal_handlers()\n\u001b[0;32m    986\u001b[0m \u001b[39m# ----------------------------\u001b[39;00m\n\u001b[0;32m    987\u001b[0m \u001b[39m# RUN THE TRAINER\u001b[39;00m\n\u001b[0;32m    988\u001b[0m \u001b[39m# ----------------------------\u001b[39;00m\n\u001b[1;32m--> 989\u001b[0m results \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_run_stage()\n\u001b[0;32m    991\u001b[0m \u001b[39m# ----------------------------\u001b[39;00m\n\u001b[0;32m    992\u001b[0m \u001b[39m# POST-Training CLEAN UP\u001b[39;00m\n\u001b[0;32m    993\u001b[0m \u001b[39m# ----------------------------\u001b[39;00m\n\u001b[0;32m    994\u001b[0m log\u001b[39m.\u001b[39mdebug(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__class__\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m: trainer tearing down\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\chris\\anaconda3\\Lib\\site-packages\\lightning\\pytorch\\trainer\\trainer.py:1033\u001b[0m, in \u001b[0;36mTrainer._run_stage\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1031\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtraining:\n\u001b[0;32m   1032\u001b[0m     \u001b[39mwith\u001b[39;00m isolate_rng():\n\u001b[1;32m-> 1033\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_run_sanity_check()\n\u001b[0;32m   1034\u001b[0m     \u001b[39mwith\u001b[39;00m torch\u001b[39m.\u001b[39mautograd\u001b[39m.\u001b[39mset_detect_anomaly(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_detect_anomaly):\n\u001b[0;32m   1035\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfit_loop\u001b[39m.\u001b[39mrun()\n",
      "File \u001b[1;32mc:\\Users\\chris\\anaconda3\\Lib\\site-packages\\lightning\\pytorch\\trainer\\trainer.py:1062\u001b[0m, in \u001b[0;36mTrainer._run_sanity_check\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1059\u001b[0m call\u001b[39m.\u001b[39m_call_callback_hooks(\u001b[39mself\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mon_sanity_check_start\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m   1061\u001b[0m \u001b[39m# run eval step\u001b[39;00m\n\u001b[1;32m-> 1062\u001b[0m val_loop\u001b[39m.\u001b[39mrun()\n\u001b[0;32m   1064\u001b[0m call\u001b[39m.\u001b[39m_call_callback_hooks(\u001b[39mself\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mon_sanity_check_end\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m   1066\u001b[0m \u001b[39m# reset logger connector\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\chris\\anaconda3\\Lib\\site-packages\\lightning\\pytorch\\loops\\utilities.py:182\u001b[0m, in \u001b[0;36m_no_grad_context.<locals>._decorator\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    180\u001b[0m     context_manager \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mno_grad\n\u001b[0;32m    181\u001b[0m \u001b[39mwith\u001b[39;00m context_manager():\n\u001b[1;32m--> 182\u001b[0m     \u001b[39mreturn\u001b[39;00m loop_run(\u001b[39mself\u001b[39m, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\chris\\anaconda3\\Lib\\site-packages\\lightning\\pytorch\\loops\\evaluation_loop.py:134\u001b[0m, in \u001b[0;36m_EvaluationLoop.run\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    132\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbatch_progress\u001b[39m.\u001b[39mis_last_batch \u001b[39m=\u001b[39m data_fetcher\u001b[39m.\u001b[39mdone\n\u001b[0;32m    133\u001b[0m     \u001b[39m# run step hooks\u001b[39;00m\n\u001b[1;32m--> 134\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_evaluation_step(batch, batch_idx, dataloader_idx, dataloader_iter)\n\u001b[0;32m    135\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mStopIteration\u001b[39;00m:\n\u001b[0;32m    136\u001b[0m     \u001b[39m# this needs to wrap the `*_step` call too (not just `next`) for `dataloader_iter` support\u001b[39;00m\n\u001b[0;32m    137\u001b[0m     \u001b[39mbreak\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\chris\\anaconda3\\Lib\\site-packages\\lightning\\pytorch\\loops\\evaluation_loop.py:391\u001b[0m, in \u001b[0;36m_EvaluationLoop._evaluation_step\u001b[1;34m(self, batch, batch_idx, dataloader_idx, dataloader_iter)\u001b[0m\n\u001b[0;32m    385\u001b[0m hook_name \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mtest_step\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mif\u001b[39;00m trainer\u001b[39m.\u001b[39mtesting \u001b[39melse\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mvalidation_step\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    386\u001b[0m step_args \u001b[39m=\u001b[39m (\n\u001b[0;32m    387\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_build_step_args_from_hook_kwargs(hook_kwargs, hook_name)\n\u001b[0;32m    388\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m using_dataloader_iter\n\u001b[0;32m    389\u001b[0m     \u001b[39melse\u001b[39;00m (dataloader_iter,)\n\u001b[0;32m    390\u001b[0m )\n\u001b[1;32m--> 391\u001b[0m output \u001b[39m=\u001b[39m call\u001b[39m.\u001b[39m_call_strategy_hook(trainer, hook_name, \u001b[39m*\u001b[39mstep_args)\n\u001b[0;32m    393\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbatch_progress\u001b[39m.\u001b[39mincrement_processed()\n\u001b[0;32m    395\u001b[0m \u001b[39mif\u001b[39;00m using_dataloader_iter:\n\u001b[0;32m    396\u001b[0m     \u001b[39m# update the hook kwargs now that the step method might have consumed the iterator\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\chris\\anaconda3\\Lib\\site-packages\\lightning\\pytorch\\trainer\\call.py:309\u001b[0m, in \u001b[0;36m_call_strategy_hook\u001b[1;34m(trainer, hook_name, *args, **kwargs)\u001b[0m\n\u001b[0;32m    306\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m    308\u001b[0m \u001b[39mwith\u001b[39;00m trainer\u001b[39m.\u001b[39mprofiler\u001b[39m.\u001b[39mprofile(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m[Strategy]\u001b[39m\u001b[39m{\u001b[39;00mtrainer\u001b[39m.\u001b[39mstrategy\u001b[39m.\u001b[39m\u001b[39m__class__\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m.\u001b[39m\u001b[39m{\u001b[39;00mhook_name\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m):\n\u001b[1;32m--> 309\u001b[0m     output \u001b[39m=\u001b[39m fn(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    311\u001b[0m \u001b[39m# restore current_fx when nested context\u001b[39;00m\n\u001b[0;32m    312\u001b[0m pl_module\u001b[39m.\u001b[39m_current_fx_name \u001b[39m=\u001b[39m prev_fx_name\n",
      "File \u001b[1;32mc:\\Users\\chris\\anaconda3\\Lib\\site-packages\\lightning\\pytorch\\strategies\\strategy.py:403\u001b[0m, in \u001b[0;36mStrategy.validation_step\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    401\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmodel \u001b[39m!=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlightning_module:\n\u001b[0;32m    402\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_redirection(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmodel, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlightning_module, \u001b[39m\"\u001b[39m\u001b[39mvalidation_step\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[1;32m--> 403\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlightning_module\u001b[39m.\u001b[39mvalidation_step(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "\u001b[1;32mc:\\Users\\chris\\OneDrive\\Code\\OntarioTechCode\\(4) Year Four\\Semester One\\Machine Learning\\Final Project\\ML-Final-Project\\Project.ipynb Cell 26\u001b[0m line \u001b[0;36m4\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/chris/OneDrive/Code/OntarioTechCode/%284%29%20Year%20Four/Semester%20One/Machine%20Learning/Final%20Project/ML-Final-Project/Project.ipynb#X34sZmlsZQ%3D%3D?line=45'>46</a>\u001b[0m outputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mforward(inputs)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/chris/OneDrive/Code/OntarioTechCode/%284%29%20Year%20Four/Semester%20One/Machine%20Learning/Final%20Project/ML-Final-Project/Project.ipynb#X34sZmlsZQ%3D%3D?line=47'>48</a>\u001b[0m \u001b[39m# get accuracy value\u001b[39;00m\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/chris/OneDrive/Code/OntarioTechCode/%284%29%20Year%20Four/Semester%20One/Machine%20Learning/Final%20Project/ML-Final-Project/Project.ipynb#X34sZmlsZQ%3D%3D?line=48'>49</a>\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39maccuracy(outputs, targets)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/chris/OneDrive/Code/OntarioTechCode/%284%29%20Year%20Four/Semester%20One/Machine%20Learning/Final%20Project/ML-Final-Project/Project.ipynb#X34sZmlsZQ%3D%3D?line=50'>51</a>\u001b[0m \u001b[39m# log the validation accuracy\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/chris/OneDrive/Code/OntarioTechCode/%284%29%20Year%20Four/Semester%20One/Machine%20Learning/Final%20Project/ML-Final-Project/Project.ipynb#X34sZmlsZQ%3D%3D?line=51'>52</a>\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlog(\u001b[39m'\u001b[39m\u001b[39mvalidation accuracy\u001b[39m\u001b[39m'\u001b[39m, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39maccuracy, prog_bar \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m)\n",
      "File \u001b[1;32mc:\\Users\\chris\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1516\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compiled_call_impl(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)  \u001b[39m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m-> 1518\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_call_impl(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\chris\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1522\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1523\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1524\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1525\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1526\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1527\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1529\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m   1530\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\chris\\anaconda3\\Lib\\site-packages\\torchmetrics\\metric.py:298\u001b[0m, in \u001b[0;36mMetric.forward\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    296\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_cache \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_full_state_update(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    297\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 298\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_cache \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_reduce_state_update(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    300\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_cache\n",
      "File \u001b[1;32mc:\\Users\\chris\\anaconda3\\Lib\\site-packages\\torchmetrics\\metric.py:367\u001b[0m, in \u001b[0;36mMetric._forward_reduce_state_update\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    364\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_enable_grad \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m  \u001b[39m# allow grads for batch computation\u001b[39;00m\n\u001b[0;32m    366\u001b[0m \u001b[39m# calculate batch state and compute batch value\u001b[39;00m\n\u001b[1;32m--> 367\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mupdate(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    368\u001b[0m batch_val \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcompute()\n\u001b[0;32m    370\u001b[0m \u001b[39m# reduce batch and global state\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\chris\\anaconda3\\Lib\\site-packages\\torchmetrics\\metric.py:457\u001b[0m, in \u001b[0;36mMetric._wrap_update.<locals>.wrapped_func\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    455\u001b[0m \u001b[39mwith\u001b[39;00m torch\u001b[39m.\u001b[39mset_grad_enabled(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_enable_grad):\n\u001b[0;32m    456\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 457\u001b[0m         update(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    458\u001b[0m     \u001b[39mexcept\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m \u001b[39mas\u001b[39;00m err:\n\u001b[0;32m    459\u001b[0m         \u001b[39mif\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mExpected all tensors to be on\u001b[39m\u001b[39m\"\u001b[39m \u001b[39min\u001b[39;00m \u001b[39mstr\u001b[39m(err):\n",
      "File \u001b[1;32mc:\\Users\\chris\\anaconda3\\Lib\\site-packages\\torchmetrics\\classification\\stat_scores.py:322\u001b[0m, in \u001b[0;36mMulticlassStatScores.update\u001b[1;34m(self, preds, target)\u001b[0m\n\u001b[0;32m    320\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Update state with predictions and targets.\"\"\"\u001b[39;00m\n\u001b[0;32m    321\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mvalidate_args:\n\u001b[1;32m--> 322\u001b[0m     _multiclass_stat_scores_tensor_validation(\n\u001b[0;32m    323\u001b[0m         preds, target, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnum_classes, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmultidim_average, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mignore_index\n\u001b[0;32m    324\u001b[0m     )\n\u001b[0;32m    325\u001b[0m preds, target \u001b[39m=\u001b[39m _multiclass_stat_scores_format(preds, target, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtop_k)\n\u001b[0;32m    326\u001b[0m tp, fp, tn, fn \u001b[39m=\u001b[39m _multiclass_stat_scores_update(\n\u001b[0;32m    327\u001b[0m     preds, target, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnum_classes, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtop_k, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39maverage, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmultidim_average, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mignore_index\n\u001b[0;32m    328\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\chris\\anaconda3\\Lib\\site-packages\\torchmetrics\\functional\\classification\\stat_scores.py:302\u001b[0m, in \u001b[0;36m_multiclass_stat_scores_tensor_validation\u001b[1;34m(preds, target, num_classes, multidim_average, ignore_index)\u001b[0m\n\u001b[0;32m    297\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m    298\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mWhen `preds` and `target` have the same shape, the shape of `preds` should \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    299\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39m atleast 2D when multidim_average is set to `samplewise`\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    300\u001b[0m         )\n\u001b[0;32m    301\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 302\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m    303\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mEither `preds` and `target` both should have the (same) shape (N, ...), or `target` should be (N, ...)\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    304\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39m and `preds` should be (N, C, ...).\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    305\u001b[0m     )\n\u001b[0;32m    307\u001b[0m num_unique_values \u001b[39m=\u001b[39m \u001b[39mlen\u001b[39m(torch\u001b[39m.\u001b[39munique(target))\n\u001b[0;32m    308\u001b[0m check \u001b[39m=\u001b[39m num_unique_values \u001b[39m>\u001b[39m num_classes \u001b[39mif\u001b[39;00m ignore_index \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39melse\u001b[39;00m num_unique_values \u001b[39m>\u001b[39m num_classes \u001b[39m+\u001b[39m \u001b[39m1\u001b[39m\n",
      "\u001b[1;31mValueError\u001b[0m: Either `preds` and `target` both should have the (same) shape (N, ...), or `target` should be (N, ...) and `preds` should be (N, C, ...)."
     ]
    }
   ],
   "source": [
    "LSTM_model = LSTM_classifier(\n",
    "    vocab_size = len(vocab),\n",
    "    embedding_dimension = 32, # hyperparameter\n",
    "    state_dimension = 64 # hyperparameter\n",
    ")\n",
    "\n",
    "LSTM_logger = CSVLogger('./lightning_logs/', 'LSTM')\n",
    "trainer = Trainer(max_epochs = 10, logger = LSTM_logger) # hyperparameter (# epochs)\n",
    "\n",
    "trainer.fit(\n",
    "    LSTM_model,\n",
    "    train_dataloaders = train_dataloader,\n",
    "    val_dataloaders = val_dataloader\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **RNN Model:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RNN_model = RNN_classifier(\n",
    "    vocab_size=len(vocab),\n",
    "    embedding_dimension = 32, # hyperparameter\n",
    "    state_dimension = 64 # hyperparameter\n",
    ")\n",
    "\n",
    "RNN_logger = CSVLogger('./lightning_logs/', 'RNN')\n",
    "trainer = Trainer(max_epochs = 10, logger = RNN_logger) # hyperparameter (# epochs)\n",
    "\n",
    "trainer.fit(\n",
    "    RNN_model,\n",
    "    train_dataloaders = train_dataloader,\n",
    "    val_dataloaders = val_dataloader\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
